# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:light
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.13.7
#   kernelspec:
#     display_name: Python 3 (ipykernel)
#     language: python
#     name: python3
# ---

# + [markdown] slideshow={"slide_type": "slide"}
# **Лекция 4**
#
# # Случайные величины и их распределения

# + [markdown] toc=true
# <h1>Содержание<span class="tocSkip"></span></h1>
# <div class="toc"><ul class="toc-item"><li><span><a href="#Понятие-случайной-величины" data-toc-modified-id="Понятие-случайной-величины-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Понятие случайной величины</a></span></li><li><span><a href="#Распределения-случайных-величин" data-toc-modified-id="Распределения-случайных-величин-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Распределения случайных величин</a></span><ul class="toc-item"><li><span><a href="#Функция-распределения" data-toc-modified-id="Функция-распределения-2.1"><span class="toc-item-num">2.1&nbsp;&nbsp;</span>Функция распределения</a></span></li><li><span><a href="#Дискретные-случайные-величины" data-toc-modified-id="Дискретные-случайные-величины-2.2"><span class="toc-item-num">2.2&nbsp;&nbsp;</span>Дискретные случайные величины</a></span></li><li><span><a href="#Абсолютно-непрерывные-случайные-величины" data-toc-modified-id="Абсолютно-непрерывные-случайные-величины-2.3"><span class="toc-item-num">2.3&nbsp;&nbsp;</span>Абсолютно непрерывные случайные величины</a></span></li></ul></li><li><span><a href="#Многомерные-распределения" data-toc-modified-id="Многомерные-распределения-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Многомерные распределения</a></span><ul class="toc-item"><li><span><a href="#Определение" data-toc-modified-id="Определение-3.1"><span class="toc-item-num">3.1&nbsp;&nbsp;</span>Определение</a></span></li><li><span><a href="#Функции-от-двух-случайных-величин" data-toc-modified-id="Функции-от-двух-случайных-величин-3.2"><span class="toc-item-num">3.2&nbsp;&nbsp;</span>Функции от двух случайных величин</a></span></li><li><span><a href="#Независимость-случайных-величин" data-toc-modified-id="Независимость-случайных-величин-3.3"><span class="toc-item-num">3.3&nbsp;&nbsp;</span>Независимость случайных величин</a></span></li></ul></li><li><span><a href="#Числовые-характеристики-случайных-величин" data-toc-modified-id="Числовые-характеристики-случайных-величин-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Числовые характеристики случайных величин</a></span><ul class="toc-item"><li><span><a href="#Математическое-ожидание" data-toc-modified-id="Математическое-ожидание-4.1"><span class="toc-item-num">4.1&nbsp;&nbsp;</span>Математическое ожидание</a></span></li><li><span><a href="#Дисперсия" data-toc-modified-id="Дисперсия-4.2"><span class="toc-item-num">4.2&nbsp;&nbsp;</span>Дисперсия</a></span></li><li><span><a href="#Ковариация" data-toc-modified-id="Ковариация-4.3"><span class="toc-item-num">4.3&nbsp;&nbsp;</span>Ковариация</a></span></li><li><span><a href="#Коэффициент-корреляции" data-toc-modified-id="Коэффициент-корреляции-4.4"><span class="toc-item-num">4.4&nbsp;&nbsp;</span>Коэффициент корреляции</a></span></li></ul></li><li><span><a href="#Оптимальная-линейная-оценка" data-toc-modified-id="Оптимальная-линейная-оценка-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Оптимальная линейная оценка</a></span></li><li><span><a href="#Источники" data-toc-modified-id="Источники-6"><span class="toc-item-num">6&nbsp;&nbsp;</span>Источники</a></span></li></ul></div>
# -

# ---

# + [markdown] slideshow={"slide_type": "slide"}
# ## Понятие случайной величины
#
# **Определение.** Функция $\xi: \Omega \rightarrow \mathbb{R}$ называется *случайной величиной*, если для любого $x \in \mathbb{R}$ множество $\{\omega : \xi(\omega) \le x\}$ является измеримым (или, что тоже самое, принадлежит $\sigma$-алгебре $\mathcal{F}$).
#
# **Замечание.** Читатель, не желающий забивать себе голову абстракциями, связанными с $\sigma$-алгебрами событий и с измеримостью, может смело считать, что любое множество элементарных исходов есть событие, и,
# следовательно, случайная величина есть произвольная функция из $\Omega$ в $\mathbb{R}$.

# + [markdown] slideshow={"slide_type": "skip"}
# ---
# -

# ## Распределения случайных величин ##
#
# ### Функция распределения ###
#
# Существуют различные типы распределений случайных величин.
# Вся вероятностная мера может быть сосредоточена в нескольких точках прямой, а может быть &laquo;размазана&raquo; по некоторому интервалу или по всей прямой.
# В зависимости от типа множества, на котором сосредоточена вероятностная мера, распределения делят на дискретные, абсолютно непрерывные, сингулярные и их смеси.
# Нас будут интересовать *дискретные* и *абсолютно непрерывные* случайные величины.
#
# **Определение.** *Распределением* случайной величины $\xi$ называется вероятностная мера $P_\xi(B) = \mathrm{P}\{\omega: \xi(\omega) \in B\}$ на множестве $B$ (борелевских) подмножеств $\mathbb{R}$.
#
# Можно представлять себе распределение случайной величины $\xi$ как соответствие между множествами $B$ и вероятностями $\mathrm{P}{\xi \in B}$.
#
# **Определение.** Функция
# $$
#   F_\xi(x) = \mathrm{P}\left\{ \omega: \xi(\omega) \le x \right\}, \quad x \in \mathbb{R}
# $$
# называется *функцией распределения* случайной величины $\xi$.

# **Свойства функции распределения:**
#
# 1. $F_\xi(x) \in [0,1]$;
# 1. $F_\xi(x)$ монотонно не убывает;
# 1. $F_\xi(x)$ непрерывна справа;
# 1. существуют пределы $\lim\limits_{x\rightarrow +\infty}F_\xi(x)=1$, $\lim\limits_{x\rightarrow -\infty}F_\xi(x)=0$.

# ### Дискретные случайные величины ###
#
# **Определение.** Случайная величина $\xi$ называется *дискретной* (имеет *дискретное распределение*), если она принимает не более чем счётное число значений, т. е. если существует конечный или счётный набор чисел $a_1, a_2, \ldots$ такой, что
# $$
#   \mathrm{P}\{\xi=a_i\} > 0 \quad \forall i.
# $$
# Если число значений *конечно*, то такая случайная величина называется *простой*.
#
# Для дискретной случайной величины $\xi$ мера $P_\xi$ сосредоточена не более чем в счётном числе точек и может быть представлена в виде
# $$
#   \mathrm{P}\{\xi \in B\} \equiv P_\xi(B) = \sum\limits_{k:x_k \in B} \mathrm{P}\{\xi=x_k\}.
# $$

# ### Абсолютно непрерывные случайные величины ###
#
# **Определение.** Случайная величина $\xi$ называется *абсолютно непрерывной*, если существует неотрицательная функция $f = f_\xi(x)$, называемая *плотностью распределения*, такая, что
#
# $$ F_\xi(x) = \int\limits_{-\infty}^x f_\xi(t) dt, \quad \forall x \in \mathbb{R}. $$
#
# **Свойства:**
#
# 1. $\forall x: f_\xi (x) \ge 0$;
# 1. $\int\limits_{-\infty}^{\infty} f_\xi(t) dt = 1$.
#
# Эти два свойства полностью характеризуют класс плотностей.
#
# **Теорема.** Если функция $f$ обладает свойствами (1) и (2), то существует вероятностное пространство и случайная величина $\xi$ на нём, для которой $f$ является плотностью распределения.

# ---

# ## Многомерные распределения

# ### Определение
#
# Пусть случайные величины $\xi_1, \ldots, \xi_n$ заданы на одном вероятностном пространстве $(\Omega, \mathcal{F}, \mathrm{P})$.
#
# **Определение.** Функция
# $$
#   F_{\xi_1, \ldots, \xi_n}(x_1, \ldots, x_n) = \mathrm{P}(\xi_1 \le x_1, \ldots, \xi_n \le x_n)
# $$
# называется *функцией совместного распределения* случайных величин $\xi_1, \ldots , \xi_n$.
#
# Далее для простоты обозначений ограничимся вектором из двух величин $(\xi, \eta)$.
#
# **Определение.** Говорят, что случайные величины $\xi, \eta$ имеют *абсолютно непрерывное совместное
# распределение*, если существует неотрицательная функция $f_{\xi, \eta}(x, y)$, называемая *плотностью*, такая, что
#
# $$
#   F_{\xi, \eta}(x, y) = \int\limits_{-\infty}^{x} \int\limits_{-\infty}^{y} f_{\xi, \eta}(t_1, t_2) dt_1 dt_2
# $$
#
# **Теорема.** Если случайные величины $\xi$ и $\eta$ имеют абсолютно непрерывное совместное распределение с плотностью $f(x, y)$, то $\xi$ и $\eta$ в отдельности также имеют абсолютно непрерывное распределение
# с плотностями:
#
# $$
#   f_{\xi}(x) = \int\limits_{-\infty}^{\infty} f_{\xi, \eta}(x, y)dy \quad \mathrm{и} \quad f_{\eta}(y) = \int\limits_{-\infty}^{\infty} f_{\xi, \eta}(x, y)dx.
# $$
#
# Соответствующие распределения называются *частными* или *маргинальными*.

# ### Функции от двух случайных величин
#
# Если нам известно совместное распределение двух или нескольких случайных величин, становится возможным отыскать распределение суммы, разности, произведения, частного, иных функций от этих случайных величин.
#
# Заметим, что знания только частных распределений двух случайных величин недостаточно для отыскания распределения, например, суммы этих величин.
# Для этого необходимо знать их *совместное распределение*.
# Распределение суммы (и любой иной функции) не определяется, вообще говоря, распределениями слагаемых: при одних и тех же распределениях слагаемых распределение суммы может быть разным в зависимости от совместного распределения слагаемых.
#
# **Пример.**
# Пусть случайная величина $\xi$ имеет стандартное нормальное распределение.
# Возьмём $\eta = -\xi$. Тогда $\eta$ тоже имеет стандартное нормальное распределение, а сумма $\xi + \eta = 0$ имеет вырожденное распределение.

# Пусть $\xi_1$ и $\xi2$ &mdash; случайные величины с плотностью совместного распределения $f_{\xi_1,\xi_2}(x_1, x_2)$.
# Пусть задана функция $g: \mathbb{R}^2 \rightarrow \mathbb{R}$.
# Требуется найти функцию (а если существует, то и плотность) распределения случайной величины $\eta = g (\xi_1,\xi_2)$.
#
# Пользуясь тем, что вероятность случайному вектору попасть в некоторую область можно вычислить как объем под графиком плотности распределения вектора над этой областью, сформулируем следующую теорему.
#
# **Теорема.** Пусть $x \in \mathbb{R}$, и область $D_x \subseteq \mathbb{R}^2$ состоит из точек $(u, v)$ таких, что $g(u, v) < x$. Тогда случайная величина $\eta = g(\xi_1,\xi_2)$ имеет функцию распределения
# $$
# F_\eta(x) = \mathrm{P}\{g(\xi_1,\xi_2) < x\} = \mathrm{P}\{(\xi_1,\xi_2) \in D_x\} = \iint\limits_{D_x} f_{\xi_1,\xi_2}(u,v)\,dudv.
# $$

# **Формула свёртки**
#
# Если случайные величины $\xi_1$ и $\xi_2$ независимы и имеют абсолютно непрерывные распределения с плотностями $f_{\xi_1}(x_1)$ и $f_{\xi_2}(x_2)$, то плотность распределения суммы $\xi_1 + \xi_2$ равна &laquo;свёртке&raquo; плотностей $f_{\xi_1}$ и $f_{\xi_2}$:
# $$
#   f_{\xi_1 +\xi_2}(t) = \int\limits_{-\infty}^{\infty} f_{\xi_1}(u) f_{\xi_2}(t-u) du
#   = \int\limits_{-\infty}^{\infty} f_{\xi_2}(u) f_{\xi_1}(t-u) du.
# $$

# *Доказательство.* Функция распределения суммы равна
# $$
#   F_{\xi_1 +\xi_2}(x) = \iint\limits_{D_x} f_{\xi_1}(x_1) f_{\xi_2}(x_2) dx_1 dx_2,
# $$
#
# где $D_x = \{(x_1,x_2) | x_1+x_2<x\}$.
#
# Интегрирование по области $D_x$ можно заменить последовательным вычислением двух интегралов: наружного &mdash; по переменной $x_1$, меняющейся в пределах от $-\infty$ до $+\infty$, и внутреннего &mdash; по переменной $x_2$, которая при каждом $x_1$ должна быть меньше, чем $x - x_1$:
# $$
#   F_{\xi_1 +\xi_2}(x) = \int\limits_{-\infty}^{\infty} \left( \int\limits_{-\infty}^{x-x_1} f_{\xi_1}(x_1) f_{\xi_2}(x_2) dx_2 \right) dx_1.
# $$
#
# Сделав замену переменной $x_2 = t - x_1$ и поменяв затем порядок интегрирования, получим
# $$
#   F_{\xi_1 +\xi_2}(x) = \int\limits_{-\infty}^{\infty} \left( \int\limits_{-\infty}^{x} f_{\xi_1}(x_1) f_{\xi_2}(t-x_1) dt \right) dx_1
#   = \int\limits_{-\infty}^{x} \left( \int\limits_{-\infty}^{\infty} f_{\xi_1}(x_1) f_{\xi_2}(t-x_1) dx_1 \right) dt.
# $$
#
# Итак, мы представили функцию распределения $F_{\xi_1 +\xi_2}(x)$ в виде $\int\limits_{-\infty}^{x} f_{\xi_1+\xi_2}(t)dt$, где
# $$
#   f_{\xi_1+\xi_2}(t) = \int\limits_{-\infty}^{\infty} f_{\xi_1}(u) f_{\xi_2}(t-u) du.
# $$

# ### Независимость случайных величин
#
# **Определение.** Случайные величины $\xi_1, \dots, \xi_n$ называются *независимыми* (в совокупности), если для любых $x_1, \dots, x_n$ справедливо равенство
# $$ F_{\xi_1, \dots, \xi_n}(x_1, \dots, x_n) = F_{\xi_1}(x_1) \cdot \ldots \cdot F_{\xi_n}(x_n).$$

# **Дискретный случай** \
# Случайные величины $\xi_1, \dots, \xi_n$ с дискретными распределениями независимы (в совокупности), если для любых чисел $a_1, \dots , a_n$ имеет место равенство
# $$ \mathrm{P}\{\xi_1=a_1, \dots, \xi_n=a_n\} = \mathrm{P}\{\xi_1=a_1\} \cdot \ldots \cdot \mathrm{P}\{\xi_n=a_n\}.$$

# **Абсолютно непрерывный случай** \
# Случайные величины $\xi_1, \dots, \xi_n$ с абсолютно непрерывными распределениями независимы (в совокупности) тогда и только тогда, когда плотность их совместного распределения существует и равна произведению плотностей каждой величины, т. е.
# $\forall x_1, \dots , x_n$:
#
# $$ f_{\xi_1, \dots, \xi_n}(x_1, \dots, x_n) = f_{\xi_1}(x_1) \cdot \ldots \cdot f_{\xi_n}(x_n). $$

# ---

# ## Числовые характеристики случайных величин ##
#
# ### Математическое ожидание ###
#
# **Определение (дискретный случай).** Пусть $\xi$ &mdash; дискретная случайная величина на пространстве $(\Omega, \mathcal{F}, \mathrm{P})$, а $X$ &mdash; множество её значений.
# Тогда *математическим ожиданием* $\xi$ называется число, равное 
# $$ \mathrm{E}\xi = \sum\limits_{x \in X}x\mathrm{P}(\xi = x), $$
# если этот ряд сходится абсолютно.
#
# **Определение (абсолютно непрерывный случай).** Пусть $\xi$ &mdash; абсолютно непрерывная случайная величина на пространстве $(\Omega, \mathcal{F}, \mathrm{P})$, а $F_\xi$, $f_\xi$ &mdash; её функция распределения и плотность.
# Тогда математическим ожиданием $\xi$ называется число, равное
# $$ \mathrm{E}\xi = \int\limits_{-\infty}^{\infty} xdF_\xi(x) = \int\limits_{-\infty}^{\infty} xf_\xi(x)dx, $$
# если этот интеграл сходится абсолютно.
#
#
# **Свойства математического ожидания:**
#
# 1. Если $\xi \ge 0$, то $\mathrm{E}\xi \ge 0$.
# 2. $\mathrm{E}(a\xi +b\eta) = a\mathrm{E}\xi +b\mathrm{E}\eta$, $\hspace{0.5em}$ $a$, $b$ &mdash; постоянные (*линейность*).
# 3. Если $\xi \ge \eta$, то $\mathrm{E}\xi \ge \mathrm{E}\eta$.
# 4. $|\mathrm{E}\xi| \le \mathrm{E}|\xi|$.
# 5. Если $\xi$ и $\eta$ независимы, то $\mathrm{E}\xi\eta = \mathrm{E}\xi \cdot \mathrm{E}\eta$.
# 6. $(\mathrm{E}|\xi\eta|)^2 \le \mathrm{E}\xi^2 \cdot \mathrm{E}\eta^2$ (*неравенство Коши&ndash;Буняковского&ndash;Шварца*).

# ### Дисперсия
#
# **Определение.** *Дисперсией* случайной величины $\xi$ называется величина
# $$ \mathrm{D} \xi = \mathrm{E} \left( \xi - \mathrm{E} \xi \right)^2. $$
#
# Величина $\sigma_\xi = +\sqrt{\mathrm{D} \xi}$ называется *стандартным отклонением* значений случайной величины $\xi$ от её среднего значения $\mathrm{E} \xi$.
#
# **Свойства дисперсии:**
#
# 1. Дисперсию случайной величины $\xi$ можно вычислить как разность математического ожидания кавдрата величины и квадрата математического ожидания: $\mathrm{D}\xi = \mathrm{E} \xi^2 - \left( \mathrm{E} \xi \right)^2$.
# 2. $\mathrm{D}\xi \ge 0$.
# 3. $\mathrm{D}(a + b\xi) = b^2 \mathrm{D}\xi$, $\hspace{0.5em}$ $a$, $b$ &mdash; постоянные.
# 4. $\mathrm{D}(\xi + \eta) = \mathrm{E} \left[ (\xi-\mathrm{E}\xi) + (\eta-\mathrm{E}\eta) \right]^2 = \mathrm{D}\xi + \mathrm{D}\eta + 2\mathrm{E}(\xi-\mathrm{E}\xi)(\eta-\mathrm{E}\eta)$

# ### Ковариация ###
#
# **Определение.** Пусть $\xi$ и  $\eta$ &mdash; две случайные величины. Их *ковариацией* называется величина
# $$
#     \mathrm{cov}(\xi, \eta) = \mathrm{E} (\xi-\mathrm{E}\xi)(\eta-\mathrm{E}\eta) = \mathrm{E}(\xi \eta) - \mathrm{E}\xi \mathrm{E}\eta.
# $$
#
# С учётом введённого обозначения для ковариации находим, что
# $$ \mathrm{D}(\xi+\eta) = \mathrm{D}\xi  + \mathrm{D}\eta +  2\mathrm{cov}(\xi, \eta).$$
#
# Если $\mathrm{cov}\left( \xi, \eta \right) = 0$, то говорят, что случайные величины $\xi$ и $\eta$ *некоррелированы*. \
# Если $\xi$ и $\eta$ некоррелированы, то дисперсия суммы $\mathrm{D}(\xi+\eta)$ равна сумме дисперсий:
# $$ \mathrm{D}(\xi+\eta) = \mathrm{D}\xi + \mathrm{D}\eta. $$
#
#
# **Замечание.** Из некоррелированности $\xi$ и $\eta$, вообще говоря, не следует их независимость. Проиллюстрируем этот факт следующим примером.
#
# > **Пример.** Пусть случайная величина $\alpha$ принимает значения 0, $\pi/2$ и $\pi$ с вероятностями 1/3. Рассмотрим две случайные величины $\xi = \sin \alpha$ и $\eta = \cos \alpha$. \
# Величины $\xi$ и $\eta$ некоррелированы, однако они не только зависимы относительно вероятности, но и *функционально зависимы*: $\xi^2 + \eta^2 = 1$.

# ### Коэффициент корреляции
#
# **Определение.** Если $\mathrm{D}\xi > 0$, $\mathrm{D}\eta > 0$, то величина
# $$
#     \rho(\xi, \eta) = \dfrac{\mathrm{cov}(\xi, \eta)}{\sqrt{\mathrm{D}\xi \cdot \mathrm{D}\eta}} = \dfrac{\mathrm{cov}(\xi, \eta)}{\sigma_\xi \cdot \sigma_\eta}
# $$
# называется *коэффициентом корреляции* случайных величин $\xi$ и $\eta$.
#
# Eсли $\rho(\xi, \eta) = \pm 1$, то величины $\xi$ и $\eta$ линейно зависимы:
# $$ \eta =a \xi + b, $$
# где $a>0$, если $\rho(\xi, \eta) = 1$, $a<0$, если $\rho(\xi, \eta) = -1$.
#
# **Определение.** Говорят, что $\xi$ и $\eta$ отрицательно коррелированы, если $\rho(\xi, \eta) < 0$; положительно коррелированы, если $\rho(\xi, \eta) > 0$; некоррелированы, если $\rho(\xi, \eta) = 0$.
#
# > **Замечание.** Коэффициент корреляции можно интерпретировать как косинус угла в некотором пространстве случайных величин, в котором скалярным произведением является ковариация.

# + [markdown] slideshow={"slide_type": "skip"}
# ---
# -

# ## Оптимальная линейная оценка
#
# Рассмотрим две случайные величины $\xi$ и $\eta$. Предположим, что наблюдению подлежит лишь случайная величина $\xi$.
# Если величины $\xi$ и $\eta$ коррелированы, то можно ожидать, что знание значений $\xi$ позволит вынести некоторые суждения и о значениях ненаблюдаемой величины $\eta$.
#
# Всякую функцию $\varphi(\xi)$ от $\xi$ будем называть *оценкой* для $\eta$.
# Будем говорить также, что *оценка* $\varphi^\ast(\xi)$ *оптимальна в среднеквадратическом смысле*, если
# $$
#   \mathrm{E}\left[\eta − \varphi^\ast(\xi)\right]^2 = \min_\varphi \mathrm{E}\left[\eta − \varphi(\xi)\right]^2,
# $$
# где минимум берётся по всем функциям $\varphi=\varphi(x)$.
#
# Покажем, как найти оптимальную оценку в классе *линейных* оценок $\lambda(\xi) = a + b\xi$.
# Для этого рассмотрим функцию $g(a, b) = \mathrm{E}(\eta − (a+b\xi))^2$.
# Дифференцируя $g(a, b)$ по $a$ и $b$, получаем
# $$
# \begin{split}
#     \frac{\partial g(a, b)}{\partial a} &= −2 \mathrm{E} \left[ \eta − (a+b\xi) \right], \\
#     \frac{\partial g(a, b)}{\partial b} &= −2 \mathrm{E} \left[ (\eta − (a+b\xi))\xi \right],
# \end{split}
# $$
# откуда, приравнивая производные к нулю, находим, что **оптимальная в среднеквадратическом смысле линейная** оценка есть $\lambda^\ast (\xi) = a^\ast + b^\ast \xi$, где
# $$
#     a^\ast = \mathrm{E}\eta − b^\ast\mathrm{E}\xi, \quad b^\ast = \frac{\mathrm{cov}(\xi, \eta)}{\mathrm{D}\xi}.
# $$
#
# Иначе говоря,
# $$
#     \lambda^\ast(\xi) = \mathrm{E}\eta + \frac{\mathrm{cov}(\xi, \eta)}{\mathrm{D}\xi} (\xi - \mathrm{E}\xi).
# $$
#
# Величина $\mathrm{E}(\eta − \lambda^\ast(\xi))^2$ называется *среднеквадратической ошибкой* оценивания.
# Простой подсчёт показывает, что эта ошибка равна
# $$
# \Delta^\ast = \mathrm{E}(\eta − \lambda^\ast(\xi))^2 = \mathrm{D}\eta − \frac{\mathrm{cov}^2(\xi, \eta)}{\mathrm{D}\xi} = \mathrm{D}\eta \cdot [1 - \rho^2(\xi, \eta)].
# $$
#
# Таким образом, чем больше по модулю коэффициент корреляции $\rho(\xi, \eta)$ между $\xi$ и $\eta$, тем меньше среднеквадратическая ошибка оценивания $\Delta^\ast$. В частности, если $|\rho(\xi, \eta)|=1$, то $\Delta^\ast = 0$. Если же случайные величины $\xi$ и $\eta$ не коррелированы (т. е. $\rho(\xi, \eta)=0$), то $\lambda^\ast(\xi) = \mathrm{E}\eta$. Таким образом, в случае отсутствия корреляции между $\xi$ и $\eta$ лучшей оценкой $\eta$ по $\xi$ является просто $\mathrm{E}\eta$.

# + [markdown] slideshow={"slide_type": "skip"}
# ---

# + [markdown] slideshow={"slide_type": "slide"}
# ## Источники
#
# 1. *Ширяев А.Н.* Вероятность &mdash; 1. &mdash; М.: МЦНМО, 2007. &mdash; 517 с.
# 1. *Чернова Н.И.* Теория вероятностей. Учебное пособие. &mdash; Новосиб. гос. ун-т, 2007. &mdash; 160 с.
# 1. *Феллер В.* Введение в теорию вероятностей и её приложения. &mdash; М.: Мир, 1964. &mdash; 498 с.
# -

