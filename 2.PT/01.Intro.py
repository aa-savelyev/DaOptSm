# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:light
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.13.7
#   kernelspec:
#     display_name: Python 3 (ipykernel)
#     language: python
#     name: python3
# ---

# **Лекция 1**
#
# # Данные и методы работы с ними

# + [markdown] toc=true
# <h1>Содержание<span class="tocSkip"></span></h1>
# <div class="toc"><ul class="toc-item"><li><span><a href="#Введение" data-toc-modified-id="Введение-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Введение</a></span><ul class="toc-item"><li><span><a href="#Превращение-мира-в-набор-данных" data-toc-modified-id="Превращение-мира-в-набор-данных-1.1"><span class="toc-item-num">1.1&nbsp;&nbsp;</span>Превращение мира в набор данных</a></span></li><li><span><a href="#Четвёртая-парадигма" data-toc-modified-id="Четвёртая-парадигма-1.2"><span class="toc-item-num">1.2&nbsp;&nbsp;</span>Четвёртая парадигма</a></span></li></ul></li><li><span><a href="#Числовые-характеристики-выборки-и-представление-данных" data-toc-modified-id="Числовые-характеристики-выборки-и-представление-данных-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Числовые характеристики выборки и представление данных</a></span><ul class="toc-item"><li><span><a href="#Числовые-характеристики" data-toc-modified-id="Числовые-характеристики-2.1"><span class="toc-item-num">2.1&nbsp;&nbsp;</span>Числовые характеристики</a></span></li><li><span><a href="#Показатели-положения-центра-распределения" data-toc-modified-id="Показатели-положения-центра-распределения-2.2"><span class="toc-item-num">2.2&nbsp;&nbsp;</span>Показатели положения центра распределения</a></span></li><li><span><a href="#Разброс-распределения-данных" data-toc-modified-id="Разброс-распределения-данных-2.3"><span class="toc-item-num">2.3&nbsp;&nbsp;</span>Разброс распределения данных</a></span></li><li><span><a href="#Взаимосвязи-между-переменными" data-toc-modified-id="Взаимосвязи-между-переменными-2.4"><span class="toc-item-num">2.4&nbsp;&nbsp;</span>Взаимосвязи между переменными</a></span></li><li><span><a href="#Визуализация" data-toc-modified-id="Визуализация-2.5"><span class="toc-item-num">2.5&nbsp;&nbsp;</span>Визуализация</a></span></li></ul></li><li><span><a href="#Вероятность-—-язык-неопределённости-и-случайности" data-toc-modified-id="Вероятность-—-язык-неопределённости-и-случайности-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Вероятность — язык неопределённости и случайности</a></span><ul class="toc-item"><li><span><a href="#Задача-Гомбо" data-toc-modified-id="Задача-Гомбо-3.1"><span class="toc-item-num">3.1&nbsp;&nbsp;</span>Задача Гомбо</a></span></li><li><span><a href="#Вероятность" data-toc-modified-id="Вероятность-3.2"><span class="toc-item-num">3.2&nbsp;&nbsp;</span>Вероятность</a></span></li><li><span><a href="#Неопределённость" data-toc-modified-id="Неопределённость-3.3"><span class="toc-item-num">3.3&nbsp;&nbsp;</span>Неопределённость</a></span></li></ul></li><li><span><a href="#Разное" data-toc-modified-id="Разное-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Разное</a></span></li><li><span><a href="#Источники" data-toc-modified-id="Источники-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Источники</a></span></li></ul></div>

# +
# Imports
import numpy as np
import scipy.stats as stats
import matplotlib.pyplot as plt

# import warnings
# warnings.filterwarnings('ignore')

# +
# Styles
import matplotlib
matplotlib.rcParams['font.size'] = 12
matplotlib.rcParams['lines.linewidth'] = 1.5
matplotlib.rcParams['lines.markersize'] = 4
cm = matplotlib.pyplot.cm.tab10  # Colormap

import seaborn
seaborn.set_style('whitegrid')

from IPython.display import Image
im_width = 1000

# +
# # %config InlineBackend.figure_formats = ['pdf']
# # %config Completer.use_jedi = False
# -

# ---

# > Все модели неверны, но некоторые полезны. Джордж Бокс

# ## Введение
#
# ###  Превращение мира в набор данных
#
# Цифры сами по себе не умеют говорить. Именно мы говорим за них. Мы наполняем их смыслом.
#
# Статистика даёт основу для интерпретации данных (которые всегда несовершенны), чтобы отличить взаимосвязи от индивидуальных особенностей, которые делают нас уникальными.
# Распространённый взгляд на статистику как на базовый &laquo;набор инструментов&raquo; в настоящее время сталкивается с серьёзными проблемами.
#
# Мы живём в век *науки о данных*, когда большие и сложные массивы данных собираются из самых обычных источников, таких как мониторинг дорожного движения, социальных сетей и покупок онлайн, а затем используются в качестве основы для технологических инноваций &mdash; например, оптимизации движения транспорта, целевой рекламы или систем рекомендации покупок.
#
# Колоссальный рост количества проводимых исследований привел к сомнениям в надёжности научной литературы и кризису воспроизводимости в науке.
# В связи с растущей доступностью больших массивов данных и удобного программного обеспечения для их анализа может показаться, что необходимость в изучении статистических методов снижается.
# Это не так.
# Увеличение объёма данных, рост количества и сложности научных исследований ещё больше затрудняют процесс формулирования соответствующих выводов.
# Большое количество данных означает, что нам надо ещё лучше осознавать, чего на самом деле стоят такие доказательства.
# Например, интенсивный анализ массивов данных может повысить вероятность ложных открытий &mdash; как вследствие систематической ошибки, присущей источнику, так и в результате выполнения множества тестов, но сообщения только о тех из них, которые выглядят интересными, то есть так называемого слепого прочёсывания данных.
#
# Все это можно объединить под термином *&laquo;грамотность в работе с данными&raquo;*, который описывает не только способность проводить статистический анализ реальных проблем, но и умение понять и критически проанализировать любые выводы, сделанные другими на основе статистики.

# ###  Четвёртая парадигма
#
# **Платонова Светлана Ипатовна.**
# *Логика научного развития: парадигма Т. Куна и четвертая парадигма Дж. Грея.*
#
# Что собой представляют первые три парадигмы научных исследований? Начиная с античности и приблизительно до Нового времени существовала экспериментальная наука, в основе которой лежали наблюдения, эксперименты с последующей систематизацией данных наблюдений и обобщением результатов экспериментов. Этот период получил название первой парадигмы. С XVII века начинается этап второй парадигмы, или этап теоретической науки, предполагающей использование теоретических моделей. На этом этапе были сформулированы законы механического движения И. Ньютона, законы движения планет И. Кеплера, уравнения Дж. Максвелла. Третья парадигма – крупномасштабное компьютерное моделирование – появилась в середине XX века [Hey, Tansley, Tolle, 2009, xviii]. Наука становится вычислительной. «Компьютеры позволили использовать методы численного моделирования, что ознаменовало появление третьей парадигмы, которая начала распространяться в последние 60 лет» [Журавлева, 2012, 118].
#
# Современный этап в развитии науки Джим Грей предложил назвать четвертой парадигмой. В чем принципиально отличается данная парадигма от трех предыдущих? Особенностью четвертой научной парадигмы является то, что наука объединяет эксперимент, теорию и моделирование. «Четвертая парадигма Грея обеспечивает интегрирующую структуру, которая позволяет первым трем взаимодействовать и усиливать друг друга» [Lynch, 2014, 177]. Одной из особенностей четвертой парадигмы является значительное увеличение объемов данных. «Объемы данных удваиваются с каждым годом в большинстве областей современной науки, и анализ этих данных становится все более и более сложным» [Szalay, Grey, 2006, 413-414]. Данных становится очень много, поэтому они требуют автоматизированного анализа. Наука имеет дело с большими данными, которые обрабатываются программным обеспечением. «Четвертому периоду свойственна возможность обработки огромных объемов экспериментальных данных, появление новых научных методов, основанных на их анализе, и доминирование синтезирующих теорий.
# Данные содержат в себе много полезной информации,но их анализ невозможен ни в каком другом виде, кроме как автоматизированного» [Журавлева, 2012, 118].
#
# Авторы книги «Четвертая парадигма» Т. Хей, С. Тэнсли, К. Толл утверждают, что эволюцию научных исследований можно представить в виде двух ветвей, направлений: вычислительная-Х и Х-информатика, где под Х понимается любая наука [Hey, Tansley, Tolle, 2009, xix]. Например, если мы посмотрим на экологию, то сейчас есть как вычислительная экология, предполагающая моделирование экологических процессов, так и экоинформатика, связанная со сбором и анализом экологической информации. Аналогично можно выделить вычислительную биологию и биоинформатику. Вычислительная биология имитирует работу биологических систем, а биоинформатика собирает и анализирует информацию из множества различных экспериментов. «Если вычислительная ветвь науки (вычислительная-Х) отвечала на вопрос «Как это может быть?», то информационная ветвь науки (Х-информатика) отвечает на вопрос: «Что это?» [Журавлева, 2012, 119].
#
# «Четвертая парадигма» науки требует от ученых пересмотра стандартных научных операций (проведение эксперимента, анализ экспериментальных данных, обобщение данных, проверка гипотез, формулирование научной теории). Одной из целей современной методологии науки является создание инструментов для поддержки всего цикла исследований – от сбора данных и их обработки до анализа данных и их визуализации. Четвертая парадигма предполагает междисциплинарную работу ученых, начиная от создания программного обеспечения до получения данных, их анализа и интерпретации.

# ---

# ## Числовые характеристики выборки и представление данных
#
# ### Числовые характеристики

# ### Показатели положения центра распределения
#
# Три толкования термина &laquo;среднее значение&raquo;:
#
# 1. Среднее арифметическое (выборочное среднее): сумма всех величин, делённая на их количество,
# 2. Медиана: значение среднего в ранжированном ряду,
# 3. Мода: чаще всего встречающееся значение в выборке.
#
# Средние значения способны сильно вводить в заблуждение, когда исходные данные имеют не симметричное распределение, а сильно перекошенное в какую-либо сторону.
#
# **Примеры:** &laquo;средний доход&raquo; и &laquo;доход среднего человека&raquo;, &laquo;средняя цена дома&raquo; и &laquo;цена среднего дома&raquo;.
#
# N-й процентиль &mdash; значение, которое не превышает N % наблюдений.
# 25-й процентиль называют первым квартилем.

# ### Разброс распределения данных
#
# 1. Размах. Размах чувствителен к экстремальным значениям.
# 2. Интерквартильный размах &mdash; разница между третьим и первым квартилями.
# 3. Стандартное (среднеквадратичное) отклонение.
#
# Полезно использовать характеристики выборки, на которые не влияют выбросы.
# Такие характеристики называются робастными и включают медиану и интерквартильный размах.
#

# ### Взаимосвязи между переменными
#
# Прямую или обратную зависимость между величинами на диаграмме рассеяния удобно выражать одним числом.
# Чаще всего для этого используется *коэффициент корреляции Пирсона*.
# Коэффициент корреляции Пирсона принимает значения от -1 до 1 и показывает, насколько близко к прямой расположены точки на диаграмме.
#
# *Ранговый коэффициент корреляции Спирмена* зависит не от конкретных численных значений, а от их рангов, то есть занимаемых ими мест, если их упорядочить по величине.
# Он может быть близок к 1 или -1, если точки близки к линии со стабильным подъёмом или понижением, даже если эта линия не является прямой.
#
# Коэффициенты корреляции &mdash; это просто характеристики связей, и их нельзя использовать для вывода о наличии взаимозависимости.
# Во многих приложениях ось $х$ представляет независимую переменную, и интерес вызывает ее влияние на зависимую переменную, которая изображается по оси $y$.
# Однако такое предположение заранее фиксирует направление влияния.

# +
x = np.linspace(0, 1, 101)
plt.figure(figsize=(6, 6))

for n in range(1,10,2):
    y = x**n
    plt.plot(x, y, label=f'$y=x^{n}$')
    print(stats.pearsonr(x, y)[0], stats.spearmanr(x, x**n)[0])

plt.xlabel('$x$')
plt.ylabel('$y$', rotation=0, ha='right')
plt.legend() 
plt.show()
# -

# ### Визуализация

# **Квартет Энскомба**
#
# Четыре набора числовых данных, у которых простые статистические свойства идентичны, но их графики существенно отличаются.
# Каждый набор состоит из 11 пар чисел.
# Квартет был составлен в 1973 году английским математиком Ф. Дж. Энскомбом для иллюстрации важности применения графиков для статистического анализа и влияния выбросов значений на свойства всего набора данных.

display(Image('./pix/01.Intro/Unstructured.png', width=0.66*im_width))

display(Image('./pix/01.Intro/Anscombe.png', width=0.66*im_width))

# **Диаграммы Каиро**
#
# [Альберто Каиро](http://albertocairo.com/)

# +
N = 2
data = []
for i in range(1,N+1):
    data.append(np.genfromtxt(f'./pix/01.Intro/dataset-{i}.csv',delimiter=',',unpack=True))

print(np.shape(data))

# +
print(f'X_m = {data[0][0].mean():.6}, {data[1][0].mean():.6}')
print(f'Y_m = {data[0][1].mean():.6}, {data[1][1].mean():.6}\n')

print(f'X_std = {data[0][0].std():.6}, {data[1][0].std():.6}')
print(f'Y_std = {data[0][1].std():.6}, {data[1][1].std():.6}\n')

Pr = [stats.pearsonr(item[0], item[1])[0] for item in data]
Sr = [stats.spearmanr(item[0], item[1])[0] for item in data]
print(f'Pearson corr.  = {Pr[0]:.6}, {Pr[1]:.6}')
print(f'Spearman corr. = {Sr[0]:.6}, {Sr[1]:.6}')

# +
# Show data
fig, axes = plt.subplots(1, N, figsize=(13,6))

for i, ax in enumerate(axes):
    ax.plot(data[i][0], data[i][1], 'ko', alpha=0.8)
    ax.set_xlim(20, 100)
    ax.set_ylim( 0, 100)
plt.show()
# -

display(Image('./pix/01.Intro/DinoSequential.gif', width=im_width))
# display(Image('../pix/01.Intro/AllDinosAnimated.gif', width=im_width))

display(Image('./pix/01.Intro/AllDinos.png', width=im_width))

# ---

# ## Вероятность &mdash; язык неопределённости и случайности
#
# ### Задача Гомбо
#
# В 1650-х годах писатель Антуан Гомбо сформулировал задачу.
#
# **Задача** \
# *Вариант 1.* Кость бросается 4 раза, игрок побеждает, если хотя бы раз выпадает шестёрка. \
# *Вариант 2.* Пара костей бросается 24 раза, игрок побеждает, если хотя бы раз выпадает пара шестёрок. \
# На что выгоднее поставить?

# +
N = int(1e4)

var_1 = np.zeros(N)
for i in range(N):
    x = np.random.randint(1, 7, 4)
    if 6 in x:
        var_1[i] = 1

prob_1 = var_1.cumsum() / range(1, N+1)
prob_1_t = 1 - (5/6)**4

# +
var_2 = np.zeros(N)
for i in range(N):
    for j in range(24):
        x = np.random.randint(1, 7, 2)
        if (x == [6, 6]).all():
            var_2[i] = 1
            break

prob_2 = var_2.cumsum() / range(1, N+1)
prob_2_t = 1 - (35/36)**24

# +
# Show data
plt.figure(figsize=(8, 6))
plt.plot(prob_1, '-', c=cm(0), label='1 die')
plt.plot(prob_2, '-', c=cm(1), label='2 dice')
plt.axhline(prob_1_t, ls='--', c=cm(0))
plt.axhline(prob_2_t, ls='--', c=cm(1))

plt.xlim([0, 1e4])
plt.ylim([0.4, 0.6])
plt.xlabel('$N$')
plt.ylabel('$P(N)$', rotation=0, ha='right')
plt.legend()
plt.show()
# -

# ### Вероятность
#
# **Классическое определение вероятности.**
# Это то, чему нас учат в школе.
# Оно основано на симметрии монет, костей, перетасованных колод карт и так далее и может быть сформулировано как &laquo;отношение числа благоприятных исходов к числу всех исходов, если все исходы равновозможны&raquo;.
# Например, вероятность выпадения единицы на правильной кости равна 1/6, потому что возможны 6 исходов, а нас устраивает один.
# Однако это определение в какой-то степени носит круговой характер, поскольку прежде мы должны уяснить, что значит равновозможны.
#
# **&laquo;Перечислительная&raquo; вероятность.**
# Предположим, в ящике лежат три белых и четыре черных носка.
# Если вытаскивать носок случайным образом, то чему равна вероятность, что он белый?
# Ответ 3/7 можно получить путем простого перечисления всех возможностей.
# Многие из нас страдали от таких вопросов в школе, и здесь мы фактически имеем дело с расширением рассмотренной вышеклассической идеи, где требуется случайный выбор из группы физических объектов.
# Мы уже использовали эту идею при описании случайного выбора элемента данных из общей генеральной совокупности.
#
# **Вероятность как частота.**
# Такое определение говорит о вероятности как о доле случаев, когда интересующее нас событие наступает в бесконечной последовательности идентичных экспериментов &mdash; в точности так как при моделировании двух вариантов игры шевалье де Мере.
# Для бесконечно повторяющихся событий это может быть разумно (хотя бы теоретически), но как насчет уникальных одноразовых событий, например скачек или завтрашней погоды?
# На деле практически любая реальная ситуация даже в принципе не может быть бесконечно воспроизводимой.
#
# **Пропенситивная интерпретация вероятности.**
# Основная идея состоит в том, что у каждой ситуации есть объективная склонность порождать какое-то событие.
# Внешне идея выглядит привлекательно: если бы вы были прозорливым существом, то могли бы сказать, что существует вероятность того, что ваш автобус скоро придет или что вас сегодня собьет машина.
# Однако у нас, простых смертных, похоже, нет возможности оценивать такие скорее метафизические &laquo;истинные шансы&raquo;.
#
# **Субъективная, или &laquo;личная&raquo;, вероятность.**
# Это степень веры конкретного человека в какое-либо событие, основанная на его нынешних знаниях.
# Обычно субъективные вероятности интерпретируются в терминах пари.
# Допустим, мне предлагают 1 фунт, если я смогу пять минут жонглировать тремя шариками, а я готов сделать на это безвозвратную ставку в 60 пенсов.
# Тогда моя личная вероятность события оценивается в 0.6. \
# Субъективная вероятность означает, что любая численная вероятность фактически *строится* в соответствии с тем, что известно в нынешней ситуации, &mdash; и на самом деле вероятность вообще не &laquo;существует&raquo; (за исключением, возможно, субатомного уровня).
# Такой подход лежит в основе **байесовской** школы статистики.

# Теория вероятностей естественным образом вступает в игру, когда мы имеем дело с ситуацией 1:
#
# 1. Когда можно считать, что данные сгенерированы каким-то рандомизирующим устройством, например, при подбрасывании монет, костей или с помощью генератора псевдослучайных чисел.
#
# Однако на практике мы можем столкнуться с ситуацией 2:
#
# 2. Когда рандомизирующее устройство выбирает уже существующий элемент данных, скажем, отбирает людей для участия в опросе.
#
# И большую часть времени наши данные появляются из ситуации 3:
#
# 3. Когда случайности нет вообще, но мы действуем так, как если бы данные были сгенерированы каким-то случайным процессом, например при интерпретации веса новорожденного ребенка вашей подруги.

# ### Неопределённость
#
# Предположим, у меня есть монета, и я спрашиваю вас, с какой вероятностью выпадет орел.
# Вы радостно отвечаете &laquo;50 процентов&raquo; или нечто подобное.
# Затем я подбрасываю ее и накрываю, пока никто не увидел результат, и снова спрашиваю, с какой вероятностью будет орел.
# Если вы типичный человек, то, как показывает мой опыт, после паузы, скорее всего, довольно неохотно скажете: &laquo;50 процентов&raquo;.
# Потом я смотрю на монету, не показывая вам, и повторяю вопрос еще раз.
# И снова, если вы относитесь к большинству, вы бормочете: &laquo;50 процентов&raquo;.
#
# Это простое упражнение показывает главное различие между двумя типами неопределенности: **стохастической неопределенностью** *до* подбрасывания монеты (когда мы имеем дело с будущим непредсказуемым событием) и **эпистемической неопределенностью** *после* подбрасывания монеты (выражением недостатка наших знаний об уже произошедшем событии).
# Это как разница между лотерейным билетом (где результат зависит от случая) и билетом мгновенной лотереи (где результат уже предопределен, просто вы его еще не знаете).
#

# ---

# ## Разное
#
# Надёжные данные &mdash; нет случайной ошибки, достоверные &mdash; систематической.
#
# &laquo;Все модели неверны, но некоторые полезны&raquo; (Джордж Бокс)
#
# Переобучение &mdash; дилемма смещения--дисперсии. \
# Переобучение происходит, когда мы заходим слишком далеко в стремлении приспособиться к локальным обстоятельствам, в порыве устранить смещение и учесть всю имеющуюся информацию.

# ---

# ## Источники
#
# 1. *Шпигельхалтер Д.* Искусство статистики. Как находить ответы в данных. &mdash; М.: Манн, Иванов и Фербер, 2021. &mdash; 448 с.

# Versions used
import sys, scipy
print('Python: {}.{}.{}'.format(*sys.version_info[:3]))
print('numpy: {}'.format(np.__version__))
print('matplotlib: {}'.format(matplotlib.__version__))
print('seaborn: {}'.format(seaborn.__version__))
print('scipy: {}'.format(scipy.__version__))
