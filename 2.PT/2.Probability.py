# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:light
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.5.2
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# + [markdown] slideshow={"slide_type": "slide"}
# # Аксиоматика теории вероятностей. Условная вероятность #

# + [markdown] toc=true
# <h1>Содержание<span class="tocSkip"></span></h1>
# <div class="toc"><ul class="toc-item"><li><span><a href="#Предмет-теории-вероятностей" data-toc-modified-id="Предмет-теории-вероятностей-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Предмет теории вероятностей</a></span></li><li><span><a href="#Вероятностная-модель" data-toc-modified-id="Вероятностная-модель-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Вероятностная модель</a></span><ul class="toc-item"><li><span><a href="#Пространство-элементарных-исходов" data-toc-modified-id="Пространство-элементарных-исходов-2.1"><span class="toc-item-num">2.1&nbsp;&nbsp;</span>Пространство элементарных исходов</a></span></li><li><span><a href="#Алгебра-и-$\mathbf{\sigma}$-алгебра-событий" data-toc-modified-id="Алгебра-и-$\mathbf{\sigma}$-алгебра-событий-2.2"><span class="toc-item-num">2.2&nbsp;&nbsp;</span>Алгебра и $\mathbf{\sigma}$-алгебра событий</a></span></li><li><span><a href="#Вероятностная-мера" data-toc-modified-id="Вероятностная-мера-2.3"><span class="toc-item-num">2.3&nbsp;&nbsp;</span>Вероятностная мера</a></span></li><li><span><a href="#Вероятностное-пространство" data-toc-modified-id="Вероятностное-пространство-2.4"><span class="toc-item-num">2.4&nbsp;&nbsp;</span>Вероятностное пространство</a></span></li><li><span><a href="#Замечания" data-toc-modified-id="Замечания-2.5"><span class="toc-item-num">2.5&nbsp;&nbsp;</span>Замечания</a></span><ul class="toc-item"><li><span><a href="#Построение-вероятностного-пространства" data-toc-modified-id="Построение-вероятностного-пространства-2.5.1"><span class="toc-item-num">2.5.1&nbsp;&nbsp;</span>Построение вероятностного пространства</a></span></li><li><span><a href="#Так-что-же-такое-вероятность?" data-toc-modified-id="Так-что-же-такое-вероятность?-2.5.2"><span class="toc-item-num">2.5.2&nbsp;&nbsp;</span>Так что же такое вероятность?</a></span></li></ul></li></ul></li><li><span><a href="#Примеры" data-toc-modified-id="Примеры-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Примеры</a></span><ul class="toc-item"><li><span><a href="#Биномиальное-распределение" data-toc-modified-id="Биномиальное-распределение-3.1"><span class="toc-item-num">3.1&nbsp;&nbsp;</span>Биномиальное распределение</a></span></li><li><span><a href="#Гипергеометрическое-распределение" data-toc-modified-id="Гипергеометрическое-распределение-3.2"><span class="toc-item-num">3.2&nbsp;&nbsp;</span>Гипергеометрическое распределение</a></span></li></ul></li><li><span><a href="#Оценка-максимального-правдоподобия" data-toc-modified-id="Оценка-максимального-правдоподобия-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Оценка максимального правдоподобия</a></span><ul class="toc-item"><li><span><a href="#Задача-об-оценке-генеральной-совокупности-по-выборке" data-toc-modified-id="Задача-об-оценке-генеральной-совокупности-по-выборке-4.1"><span class="toc-item-num">4.1&nbsp;&nbsp;</span>Задача об оценке генеральной совокупности по выборке</a></span></li></ul></li><li><span><a href="#Условная-вероятность.-Независимость" data-toc-modified-id="Условная-вероятность.-Независимость-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Условная вероятность. Независимость</a></span><ul class="toc-item"><li><span><a href="#Условная-вероятность" data-toc-modified-id="Условная-вероятность-5.1"><span class="toc-item-num">5.1&nbsp;&nbsp;</span>Условная вероятность</a></span><ul class="toc-item"><li><span><a href="#Свойства-условной-вероятности" data-toc-modified-id="Свойства-условной-вероятности-5.1.1"><span class="toc-item-num">5.1.1&nbsp;&nbsp;</span>Свойства условной вероятности</a></span></li><li><span><a href="#Формула-полной-вероятности" data-toc-modified-id="Формула-полной-вероятности-5.1.2"><span class="toc-item-num">5.1.2&nbsp;&nbsp;</span>Формула полной вероятности</a></span></li><li><span><a href="#Формула-умножения-вероятностей" data-toc-modified-id="Формула-умножения-вероятностей-5.1.3"><span class="toc-item-num">5.1.3&nbsp;&nbsp;</span>Формула умножения вероятностей</a></span></li></ul></li><li><span><a href="#Теорема-Байеса" data-toc-modified-id="Теорема-Байеса-5.2"><span class="toc-item-num">5.2&nbsp;&nbsp;</span>Теорема Байеса</a></span></li><li><span><a href="#Независимость" data-toc-modified-id="Независимость-5.3"><span class="toc-item-num">5.3&nbsp;&nbsp;</span>Независимость</a></span></li><li><span><a href="#Примеры" data-toc-modified-id="Примеры-5.4"><span class="toc-item-num">5.4&nbsp;&nbsp;</span>Примеры</a></span></li><li><span><a href="#Отношение-шансов-и-отношение-правдоподобия" data-toc-modified-id="Отношение-шансов-и-отношение-правдоподобия-5.5"><span class="toc-item-num">5.5&nbsp;&nbsp;</span>Отношение шансов и отношение правдоподобия</a></span></li></ul></li><li><span><a href="#Источники" data-toc-modified-id="Источники-6"><span class="toc-item-num">6&nbsp;&nbsp;</span>Источники</a></span></li></ul></div>
# -

# Imports
import numpy as np
import matplotlib.pyplot as plt

# +
# Styles
import warnings
# warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings('ignore')

import matplotlib
matplotlib.rcParams['font.size'] = 14
matplotlib.rcParams['lines.linewidth'] = 1.5
matplotlib.rcParams['lines.markersize'] = 4
cm = plt.cm.tab10  # Colormap

import seaborn
seaborn.set_style('whitegrid')
# -

# ---

# + [markdown] slideshow={"slide_type": "slide"}
# ## Предмет теории вероятностей ##
#
# Предметом теории вероятностей является математический анализ случайных явлений &mdash; эмпирических феноменов, которые (при заданном &laquo;комплексе условий&raquo;) могут быть охарактеризованы тем, что
#
# - для них отсутствует *детерминистическая регулярность* (наблюдения над ними не всегда приводят к одним и тем же исходам)
#
# и в то же самое время
#
# - они обладают некоторой *статистической регулярностью* (проявляющейся в статистической устойчивости частот).
#
# Поясним сказанное на классическом примере &laquo;честного&raquo; подбрасывания &laquo;правильной&raquo; монеты.
# Ясно, что заранее невозможно с определенностью предсказать исход каждого подбрасывания.
# Результаты отдельных экспериментов носят крайне нерегулярный характер (то &laquo;герб&raquo;, то &laquo;решетка&raquo;), и кажется, что это лишает нас возможности познать какие-либо закономерности, связанные с этими экспериментами.
# Однако, если провести большое число &laquo;независимых&raquo; подбрасываний, то можно заметить, что для &laquo;правильной&raquo; монеты будет наблюдаться вполне определенная статистической регулярность, проявляющаяся в том, что частота выпадания &laquo;герба&raquo; будет &laquo;близка&raquo; к $1/2$.

# + [markdown] slideshow={"slide_type": "skip"}
# ---
# -

# ## Вероятностная модель ##
#
# Согласно аксиоматике Колмогорова первоначальным объектом теории вероятностей является *вероятностное пространство* $(\Omega, \mathcal{F}, \mathrm{P})$.
# Здесь $\Omega$ &mdash; это множество, состоящее из элементарных событий $\omega$, с выделенной на нём системой его подмножеств (событий) $\mathcal{F}$, образующих $\sigma$-алгебру, а $\mathrm{P}$ &mdash; вероятностная мера (вероятность), определённая на множествах из $\mathcal{F}$.
#
# А теперь подробнее.

# + [markdown] slideshow={"slide_type": "notes"}
# ### Пространство элементарных исходов ###
#
# **Определение**. *Пространством элементарных исходов* называется множество $\Omega$, содержащее все возможные *взаимоисключающие* результаты данного случайного эксперимента.
# Элементы множества $\Omega$ называются элементарными исходами и обозначаются буквой $\omega$.
#
# Элементарный исход &mdash; это мельчайший неделимый результат эксперимента. \
# Выделение пространства элементарных исходов представляет собой первый шаг в формулировании понятия *вероятностной модели* (вероятностной &laquo;теории&raquo;) того или иного эксперимента.

# + [markdown] slideshow={"slide_type": "notes"}
# **Примеры:**
#
# - однократное подбрасывание монеты (пространство исходов состоит из двух точек: Г &mdash; &laquo;герб&raquo;, Р &mdash; &laquo;решетка&raquo;);
# - n-кратное подбрасывание монеты;
# - выбор шаров с возвращением (упорядоченные и неупорядоченные выборки);
# - выбор шаров без возвращения (упорядоченные и неупорядоченные выборки).

# + [markdown] slideshow={"slide_type": "notes"}
# ### Алгебра и $\mathbf{\sigma}$-алгебра событий ###
#
# Наряду с понятием пространства элементарных исходов введём теперь важное понятие события, лежащее в основе построения всякой
# вероятностной модели рассматриваемого эксперимента.
#
# Мы собираемся определить набор подмножеств множества $\Omega$, которые будут называться событиями, и затем задать вероятность как функцию, определённую *только* на множестве событий.
#
# *Событиями* мы будем называть не любые подмножества $\Omega$, а лишь элементы некоторого выделенного набора подмножеств множества $\Omega$.
# В качестве наборов событий целесообразно рассматривать системы множеств, являющиеся *алгебрами*.
# Для этого необходимо позаботиться, чтобы этот набор подмножеств был *замкнут* относительно операций объединения, пересечения и дополнения.
#
# **Определение.** Множество $\mathcal{F}$, элементами которого являются подмножества множества $\Omega$ называется $\sigma$-*алгеброй*, если оно удовлетворяет следующим аксиомам:
#
# 1. $\Omega \in \mathcal{F}$ ($\sigma$-алгебра содержит *достоверное событие*);
# 2. если $A \in \mathcal{F}$, то $\overline{A} \in \mathcal{F}$ (вместе с любым множеством $\sigma$-алгебра содержит противоположное к нему);
# 3. если $A_1,\,A_2,\,\ldots \in \mathcal{F}$, то $\bigcup\limits_{i=1}^{\infty}A_i \in \mathcal{F}$ (вместе с любым *счётным* набором событий $\sigma$-алгебра содержит их объединение).
# -

# **Свойства:**
#
# 1. Из аксиом 1 и 2 следует, что пустое множество $\emptyset = \overline{\Omega}$ также содержится в $\mathcal{F}$, т. е. алгебра содержит и *невозможное событие*. \
# 1. Из аксиом 2 и 3 следует, что вместе с любым счётным набором событий $\sigma$-алгебра содержит не только их объединение $\bigcup\limits_{i=1}^{\infty}A_i$, но и их пересечение $\bigcap\limits_{i=1}^{\infty}A_i$.
#
# **Примеры:**
#
# 1. $\mathcal{F} = \{ \Omega, \emptyset \}$ &mdash; система, состоящая из $\Omega$ и пустого множества (так называемая тривиальная алгебра);
# 2. $\mathcal{F} = \{ A, \overline{A}, \Omega, \emptyset \}$ &mdash; система, порождённая событием $A$;
# 3. $\mathcal{F} = \{ A: A \subseteq \Omega \}$ &mdash; совокупность всех подмножеств $\Omega$ (обозначается $2^\Omega$).
#
# > *Упражнение.* Доказать, что если $\Omega$ состоит из $n$ элементов, то в множестве всех его подмножеств ровно $2^n$ элементов.

# + [markdown] slideshow={"slide_type": "notes"}
# ### Вероятностная мера ###
#
# Пока мы сделали два первых шага к построению вероятностной модели эксперимента: выделили пространство исходов $\Omega$ и некоторую систему $\mathcal{F}$ его подмножеств, образующих $\sigma$-алгебру и называемых событиями.
# Сделаем теперь следующий шаг, а именно введём вероятностную меру.
#
# **Определение.** Пусть $\Omega$ &mdash; непустое множество, а $\mathcal{F}$ &mdash; $\sigma$-алгебра его подмножеств. Функция $\mathrm{P}: \mathcal{F} \rightarrow \mathbb{R}$ называется *вероятностной мерой*, если она удовлетворяет следующим аксиомам:
#
# 1. $\mathrm{P}(A) \ge 0$, $A \in \mathcal{F}$ (неотрицательность);
# 1. $\mathrm{P}\left( \bigcup\limits_{i=1}^{\infty}A_i \right) = \sum\limits_{i=1}^{\infty}\mathrm{P}(A_i)$,
# где $A_i \in \mathcal{F}$, $A_i \cap A_j = \emptyset$, $i \ne j$ (счётная или $\sigma$-аддитивность) \
#    (для любого счётного набора попарно несовместных событий мера их объединения равна сумме их мер);
# 1. $\mathrm{P}(\Omega) = 1$ (нормированность).
#
# *Замечание 1.* Аксиомы 1 и 2 задают *меру* как неотрицательную $\sigma$-аддитивную функцию множеств, аксиома 3 определяет вероятность как *нормированную меру*.
#
# *Замечание 2.* Существуют примеры неизмеримых множеств, например, *множество Витали*.
# -

# **Свойства:**
#
# 1. $\mathrm{P}(\emptyset) = 0$;
# 1. $\mathrm{P}(\overline{A}) = 1 - \mathrm{P}(A)$;
# 1. $\mathrm{P}(A \cup B) = \mathrm{P}(A) + \mathrm{P}(B) - \mathrm{P}(A \cap B)$;
# 1. $\mathrm{P}\left( \bigcup\limits_{i=1}^{n}A_i \right) = \sum\limits_{i}\mathrm{P}(A_i) - \sum\limits_{i<j}\mathrm{P}(A_i \cap A_j) + \sum\limits_{i<j<k}\mathrm{P}(A_i \cap A_j \cap A_k) + \ldots + (-1)^{n-1} \mathrm{P}\left( \bigcap\limits_{i=1}^{n}A_i \right)$ &mdash; формула включения-исключения.

# + [markdown] slideshow={"slide_type": "subslide"}
# ### Вероятностное пространство ###
#
# **Определение.** Тройка объектов
#
# $$ \left( \Omega, \mathcal{F}, \mathrm{P} \right), $$
#
# где $\Omega$ &mdash; множество элементарных исходов, $\mathcal{F}$ &mdash; $\sigma$-алгебра его подмножеств и $\mathrm{P}$ &mdash; вероятностная мера на $\mathcal{F}$, называется *вероятностным пространством*.

# + [markdown] slideshow={"slide_type": "notes"}
# ### Замечания ###
#
# #### Построение вероятностного пространства ####
#
# При построении вероятностных моделей в конкретных ситуациях выделение пространства элементарных событий $\Omega$ и алгебры событий $\mathcal{F}$, как правило, не является сложной задачей.
# При этом в элементарной теории вероятностей в качестве алгебры $\mathcal{F}$ обычно берется алгебра *всех* подмножеств $\Omega$.
# Труднее обстоит дело с вопросом о том, как задавать вероятности элементарных событий.
# В сущности, ответ на этот вопрос лежит вне рамок теории вероятностей, и мы его подробно не рассматриваем, считая, что основной нашей задачей является не вопрос о том, как приписывать исходам те или иные вероятности, а *вычисление* вероятностей
# сложных событий (событий из $\mathcal{F}$) по вероятностям элементарных событий.
#
# С математической точки зрения ясно, что в случае конечного пространства элементарных событий с помощью приписывания исходам $\omega_1, \ldots , \omega_N$ неотрицательных чисел $p_1, \ldots , p_N$, удовлетворяющих условию $p_1 + \ldots + p_N = 1$, мы получаем все мыслимые (конечные) вероятностные пространства.
#
# *Правильность* же назначенных для конкретной ситуации значений $p_1, \ldots , p_N$ может быть до известной степени проверена с помощью *закона больших чисел*, согласно которому в длинных сериях &laquo;независимых&raquo; экспериментов, происходящих при одинаковых условиях, частоты появления элементарных событий &laquo;близки&raquo; к их вероятностям.
# -

# #### Так что же такое вероятность? ####
#
# **Классическое определение вероятности.**
# Это то, чему нас учат в школе.
# Оно основано на симметрии монет, костей, перетасованных колод карт и так далее и может быть сформулировано как &laquo;отношение числа благоприятных исходов к числу всех исходов, если все исходы равновозможны&raquo;.
# Например, вероятность выпадения единицы на правильной кости равна 1/6, потому что возможны 6 исходов, а нас
# устраивает один.
# Однако это определение в какой-то степени носит круговой характер, поскольку прежде мы должны уяснить, что значит
# равновозможны.
#
# **&laquo;Перечислительная&raquo; вероятность.**
# Предположим, в ящике лежат три белых и четыре черных носка.
# Если вытаскивать носок случайным образом, то чему равна вероятность, что он белый?
# Ответ 3/7 можно получить путем простого перечисления всех возможностей.
# Многие из нас страдали от таких вопросов в школе, и здесь мы фактически имеем дело с расширением рассмотренной выше
# классической идеи, где требуется случайный выбор из группы физических объектов.
# Мы уже использовали эту идею при описании случайного выбора элемента данных из общей генеральной совокупности.
#
# **Вероятность как частота.**
# Такое определение говорит о вероятности как о доле случаев, когда интересующее нас событие наступает в бесконечной последовательности идентичных экспериментов &mdash; в точности так как при моделировании двух вариантов игры шевалье де Мере.
# Для бесконечно повторяющихся событий это может быть разумно (хотя бы теоретически), но как насчет уникальных одноразовых событий, например скачек или завтрашней погоды?
# На деле практически любая реальная ситуация даже в принципе не может быть бесконечно воспроизводимой.
#
# **Субъективная, или &laquo;личная&raquo;, вероятность.**
# Это степень веры конкретного человека в какое-либо событие, основанная на его нынешних знаниях.
# Субъективная вероятность означает, что любая численная вероятность фактически *строится* в соответствии с тем, что известно в нынешней ситуации, &mdash; и на самом деле вероятность вообще не &laquo;существует&raquo; (за исключением, возможно, субатомного уровня).
# Такой подход лежит в основе **байесовской** школы статистики.

# + [markdown] slideshow={"slide_type": "skip"}
# ---

# + [markdown] slideshow={"slide_type": "slide"}
# ## Примеры ##

# + [markdown] slideshow={"slide_type": "notes"}
# ### Биномиальное распределение ###
#
# Предположим, что монета подбрасывается $n$ раз и результат наблюдений записывается в виде упорядоченного
# набора $(a_1, \ldots, a_n)$, где $a_i = 1$ в случае появления «герба» («успех») и $a_i = 0$ в случае появления «решетки» («неуспех»).
# Пространство всех исходов имеет следующую структуру:
# $$ \Omega= \left\{ \omega: \omega = (a_1, \ldots, a_n), \quad a_i = 0 \; \mathrm{или} \; 1 \right\}. $$
#
# Припишем каждому элементарному событию $\omega = (a_1, \ldots, a_n)$ вероятность (&laquo;вес&raquo;)
# $$ p(\omega) = p^{\sum a_i} q^{n-\sum a_i}, $$
# где неотрицательные числа $p$ и $q$ таковы, что $p + q = 1$.
#
# Итак, пространство $\Omega$ вместе с системой $\mathcal{A}$ всех его подмножеств и вероятностями $\mathrm{P}(A) = \sum\limits_{\omega \in A}p(\omega), \; A \in \mathcal{A}$ (в частности, $\mathrm{P}(\{\omega\}) = p(\omega), \; \omega \in \Omega$) определяет некоторую вероятностную модель.
# Естественно назвать её *вероятностной моделью, описывающей $n$-кратное подбрасывание монеты*.
#
# Введём в рассмотрение события
# $$ 
#     A_k = \left\{\omega: \omega=(a_1, \ldots, a_n), a_1 + \ldots + a_n = k\right\}, \quad k = 0, 1, \ldots, n,
# $$
# означающие, что произойдет в точности $k$ &laquo;успехов&raquo;. Тогда вероятность события $A_k$ равна
# $$ \mathrm{P}(A_k) = C_n^k p^k q^{n-k}, $$
# причём $\sum\limits_{k=0}^n \mathrm{P}(A_k) = 1$.
#
# Набор вероятностей $\{\mathrm{P}(A_0), \ldots,\mathrm{P}(A_n)\}$ называется *биномиальным распределением* (числа &laquo;успехов&raquo; в выборке объёма $n$).

# + [markdown] slideshow={"slide_type": "subslide"}
# ### Гипергеометрическое распределение ###
#
# Рассмотрим урну, содержащую $N$ шаров, из которых $M$ шаров имеют белый цвет.
# Предположим, что осуществляется выбор без возвращения объёма $n < N$.
# Вероятность события $B_m$, состоящего в том, что $m$ шаров из выборки имеют белый цвет равна
#
# $$ \mathrm{P}(B_m) = \dfrac{C_M^m C_{N-M}^{n-m}}{C_N^n}. $$
#
# Набор вероятностей $\{\mathrm{P}(B_0), \ldots,\mathrm{P}(B_n)\}$ носит название многомерного гипергеометрического распределения.
# -

# ## Оценка максимального правдоподобия ##
#
# Пусть $N$ &mdash; размер некоторой популяции, который требуется оценить &laquo;минимальными средствами&raquo; без простого пересчета всех элементов этой совокупности.
# Подобного рода вопрос интересен, например, при оценке числа жителей в той или иной стране, городе и т. д.
#
# В 1786 г. Лаплас для оценки числа $N$ жителей Франции предложил следующий метод.
#
# 1. Выберем некоторое число $M$, элементов популяции и пометим их.
# 2. Возвратим их в основную совокупность и предположим, что они &laquo;хорошо перемешаны&raquo; с немаркированными элементами.
# 3. После этого возьмём из &laquo;перемешанной&raquo; популяции $n$ элементов.
# 4. Пусть среди них $m$ элементов оказались маркированными.
#
# Вероятность $\mathrm{P}(B_m(N))$ задается формулой гипергеометрического распределения:
# $$
#     \mathrm{P}(B_m(N)) = \frac{C_M^m C_{N-M}^{n-m}}{C_N^n}. \tag{1}\label{eq:prob}
# $$
#
# Нам известны числа $M$, $n$ и $m$, а $N$ (размер популяциии) &mdash; нет, его требуется оценить.
#
# Для каждого частного набора наблюдений $M$, $n$ и $m$ значение $N$, при котором вероятность $\mathrm{P}(B_m(N))$ максимальна, называется **оценкой максимального правдоподобия**.
# Обозначим наиболее правдоподобное значение через $\hat{N}$.
#
# Можно показать, что $\hat{N}$ определяется формулой ($[\cdot]$ &mdash; целая часть):
# $$ \hat{N} = \left[\dfrac{Mn}{m}\right]. \tag{2}\label{eq:max} $$
#
# >*Задание.* Получить формулу $\eqref{eq:max}$. \
# Подсказка: можно воспользоваться формулой Стирлинга $n! \sim \sqrt{2 \pi n}\left( \dfrac{n}{e} \right)^n$.

# ### Задача об оценке генеральной совокупности по выборке ###
#
# Применим метод максимального правдоподобия для оценки количества рыб в озере.
# Пусть, например, $M=1000$, $n=1000$, а $m=100$.
# Тогда всё, что нам достоверно известно о количестве рыб, это $N \ge n + M - m = 1900$.
# Вообще говоря, не исключено, что в озере их ровно $1900$.
# Однако, отправляясь от этой гипотезы, мы придём к выводу, что случилось событие фантастически малой вероятности.
# Действительно, вероятность того, что выборка объёмом $n=1000$ из генеральной совокупности объёма $N=1900$ будет содержать $m=100$ маркированных объектов, если общее число маркированных объектов $M=1000$, по формуле ([1](#mjx-eqn-eq:prob)) равна
# $$
#     \mathrm{P}(B_{100}(1900)) = \frac{C_{1000}^{100} C_{900}^{900}}{C_{1900}^{1000}} = \frac{(1000!)^2}{100! \, 1900!} \sim 10^{-430}.
# $$
#
# Аналогичное рассуждение заставляет нас откинуть гипотезу о том, что $N$ очень велико, скажем равно миллиону ($\mathrm{P}(B_{100}(10^6)) \sim 10^{-163}$).
#

# +
import mpmath
from scipy.stats import hypergeom

P_1e2 = mpmath.fac(1000)**2 / mpmath.fac(100) / mpmath.fac(1900)
print(P_1e2)

P_1e6 = hypergeom.pmf(100, 1e6, 1000, 1000)
print(P_1e6)


# -

# Обозначим вероятность события $B_{100}(N)$ через $P(N)$ и построим её зависимость от $N$.

# +
def P(x):
    return hypergeom.pmf(100, x, 1000, 1000)

# Generate data
X = np.arange(5000, 28000, 100)
Y = P(X)
# -

# Show data
plt.figure(figsize=(8, 6))
plt.plot(X, Y, '-')
plt.yscale('log')
plt.xlabel('$N$')
plt.ylabel('$P(N)$', rotation=0, ha='right')
plt.show()

# +
# Find maximum likelihood estimation
mle_idx = np.argmax(Y)
x_mle = X[mle_idx]
y_mle = Y[mle_idx]

print(x_mle, y_mle)
# -

# В нашем примере оценкой максимального правдоподобия для количества рыб в озере является число $\hat{N} = 10^4$, а вероятность соответствующего события $\mathrm{P}(B_{100}(10^4)) \approx 0.044$.

# + [markdown] slideshow={"slide_type": "skip"}
# ---

# + [markdown] slideshow={"slide_type": "slide"}
# ## Условная вероятность. Независимость ##
#
# ### Условная вероятность ###
#
# Игральная кость подбрасывается один раз.
# Известно, что выпало более трёх очков. Какова при этом вероятность того, что выпало нечётное число очков?
#
# Пусть событие $A = \{4, 5, 6\}$ означает, что выпало более трёх очков, событие $B = \{1, 3, 5\}$ &mdash; выпало нечётное число очков.
# Как понимать вероятность события $B$, если известно, что $A$ случилось?
# Знаем, что произошло событие $A$, но всё равно не знаем, что именно выпало на кости.
# Однако теперь возможностей осталось только три : могло выпасть 4, 5 или 6 очков.
# Событию $B$ из этих равновозможных исходов благоприятен единственный исход: выпадение пяти очков.
# Поэтому искомая вероятность равна $1/3$.
#
# Итак, при вычислении условной вероятности события $B$ при случившемся событии $A$ мы ищем долю исходов, благоприятствующих $B$, среди всех исходов события $A$.
# Эту условную вероятность будем обозначать $\mathrm{P}(B|A)$.
#
# Дадим теперь определение условной вероятности, согласующееся с интуитивными представлениями о ней.
#
# **Определение.** Условной вероятностью события $B$ при условии события $A$ с $\mathrm{P}(A)>0$ называется величина
# $$ \mathrm{P}(B|A) = \dfrac{\mathrm{P}(AB)}{\mathrm{P}(A)}. $$

# + [markdown] slideshow={"slide_type": "subslide"}
# #### Свойства условной вероятности ####
#
# Все общие теоремы о вероятностях верны также и для условных вероятностей, если эти условные вероятности берутся при одном и том же условии $A$.
#
# 1. $\mathrm{P}(A|A) = 1$,
# 1. $\mathrm{P}(\emptyset|A) = 0$,
# 1. $\mathrm{P}(B|A) = 1$, $B \supseteq A$,
# 1. $\mathrm{P}(B_1 + B_2|A) = \mathrm{P}(B_1|A) + \mathrm{P}(B_2|A) - \mathrm{P}(B_1 B_2|A)$.
#
# > **Пример.** Рассмотрим семьи, имеющие двух детей. Спрашивается, какова вероятность того, что в семье оба ребенка мальчики, в предположении, что:
# 1. старший ребенок &mdash; мальчик (*1/2*);
# 2. по крайней мере один из детей &mdash; мальчик (*1/3*)?

# + [markdown] slideshow={"slide_type": "subslide"}
# #### Формула полной вероятности ####
#
# Рассмотрим *полную группу несовместимых (непересекающихся) событий* $\mathcal{D} = \{A_1, \dots, A_n\}$.
# Имеет место *формула полной вероятности*
# $$ \mathrm{P}(B) = \sum_{i=1}^n \mathrm{P}(B|A_i) \mathrm{P}(A_i). $$
#
# > **Пример.** В урне имеется $M$ шаров, среди которых $m$ &laquo;счастливых&raquo;. Спрашивается, какова вероятность извлечь на втором шаге &laquo;счастливый&raquo; шар (предполагается, что качество первого извлеченного шара неизвестно). \
# *Ответ:* $\frac{m}{M}$.
# -

# #### Формула умножения вероятностей ####
#
# Из определения условной вероятности получим формулу *умножения вероятностей*:
# $$ \mathrm{P}(AB) = \mathrm{P}(B|A) \mathrm{P}(A). $$
#
# Формула умножения вероятностей обобщается по индукции:
# $$ \mathrm{P}(A_1 \dots A_n) = \mathrm{P}(A_1) \mathrm{P}(A_2|A_1) \dots \mathrm{P}(A_n|A_1 \dots A_{n-1}). $$

# + [markdown] slideshow={"slide_type": "subslide"}
# ### Теорема Байеса ###
#
# Из формул $\mathrm{P}(B|A) = \dfrac{\mathrm{P}(AB)}{\mathrm{P}(A)}$ и $\mathrm{P}(A|B) = \dfrac{\mathrm{P}(AB)}{\mathrm{P}(B)}$ получаем **формулу Байеса**:
# $$ \mathrm{P}(A|B) = \dfrac{\mathrm{P}(A) \mathrm{P}(B|A)}{\mathrm{P}(B)}. $$
#
# Если события $A_1, \dots, A_n$ образуют разбиение $\Omega$, то из формул полной вероятности и Байеса следует **теорема Байеса**:
# $$ \mathrm{P}(A_i|B) = \frac{\mathrm{P}(A_i) \mathrm{P}(B|A_i)}{\sum_{j=1}^{n} \mathrm{P}(A_j) \mathrm{P}(B|A_j)}. $$
# -

# В статистических применениях события $H_1, \dots, H_n$ образующие &laquo;полную группу событий&raquo; ($H_1 + \dots + H_n = \Omega$), часто называют &laquo;гипотезами&raquo;, а $\mathrm{P}(H_i)$ &mdash; *априорной* вероятностью гипотезы $H_i$.
# Условная вероятность $\mathrm{P}(H_i|D)$ трактуется как *апостериорная* вероятность гипотезы $H_i$ после наступления события (наблюдения данных) $D$.
#
# Формула Байеса даёт возможность получить ответ на вопрос о том, как изменится постериорная вероятность $\mathrm{P}(H|D)$ гипотезы $H$ при данных наблюдения $D$ (т.е. оценка, полученная после изучения новых экспериментальных данных), при условии, что известны априорная вероятность этой гипотезы $\mathrm{P}(H)$ (т.е. оценка, полученная без учета данных $D$), вероятность получения данных $\mathrm{P}(D)$ и условная вероятность $\mathrm{P}(D|H)$ получить данные $D$, если гипотеза $H$ выполнена. \
# В этом случае величину $\mathrm{P}(D|H)$ называют *правдоподобием* гипотезы $H$ с учётом данных $D$.

# + [markdown] slideshow={"slide_type": "subslide"}
# ### Независимость ###
#
# **Определение.** События $A$ и $B$ называются *независимыми* или *статистически независимыми* (относительно вероятности $\mathrm{P}$), если
# $$ \mathrm{P}(AB) = \mathrm{P}(A) \cdot \mathrm{P}(B). $$
#
# Для независимых событий получаем закономерный результат:
# $$ \mathrm{P}(B|A) = \dfrac{\mathrm{P}(AB)}{\mathrm{P}(A)} = \dfrac{\mathrm{P}(A)\mathrm{P}(B)}{\mathrm{P}(A)} = \mathrm{P}(B). $$
# -

# ### Примеры ###
#
# **Пример 1.**
#
# У вас в кармане три монеты: на одной два орла, на другой две решки, третья обычная.
# Вы наугад вытаскиваете монету, подбрасываете ее, и выпадает орёл.
# Какова вероятность, что на другой стороне монеты тоже орёл?
#
# Многие бы решили, что ответ &mdash; $1/2$, поскольку монета либо обычная, либо с двумя орлами, и вероятность выбрать одну из них
# одинакова.
# Существует много способов это проверить, но проще всего использовать идею с ожидаемыми количествами.
#
# Подумаем, чего можно ожидать, если проделать такой эксперимент шесть раз.
# В среднем каждая монета будет выбрана дважды, и каждая из сторон выпадет по разу.
# Орёл выпадает в трех случаях, причем в двух на второй стороне также будет орёл.
# Поэтому вероятность того, что на второй стороне монеты тоже орёл, равна $2/3$, а не $1/2$.
# По сути, выпадение орла повышает вероятность выбора монеты с двумя орлами, ведь у такой монеты есть два варианта упасть орлом
# вверх, а у симметричной &mdash; только один.

# **Пример 2.**
#
# Используемый в эксперименте детектор сложных молекул правильно различает молекулы $A$ и $B$ в $90\,\%$ случаев, т.е. $\mathrm{P}(a|A) = 0.9$, $\mathrm{P}(b|B) = 0.9$, где $a$ и $b$ означают результат тестирования для соответствующей молекулы.
# Следовательно, вероятности ошибочных результатов равны $\mathrm{P}(b|A) = \mathrm{P}(a|B) = 0.1$.
# Эти цифры характеризуют аппаратную надежность тестов.
# Предположим, что молекулы типов $A$ и $B$ в потоке частиц встречаются с вероятностями $\mathrm{P}(A) = 0.95$ и $\mathrm{P}(B) = 0.05$ соответственно.
# Какова вероятность $\mathrm{P}(B|b)$ того, что молекула действительно имеет тип $B$ при условии, что об этом свидетельствует результат тестирования $b$?
#
# $$
#   \mathrm{P}(B|b) = \mathrm{P}(B) \dfrac{\mathrm{P}(b|B)}{\mathrm{P}(b)} = \mathrm{P}(B) \dfrac{\mathrm{P}(b|B)}{\mathrm{P}(B)\mathrm{P}(b|B) + \mathrm{P}(A)\mathrm{P}(b|A)} = 0.05\dfrac{0.9}{0.05 \cdot 0.9 + 0.95 \cdot 0.1} = 0.321
# $$

p1 = 0.05*0.9/(0.05*0.9 + 0.95*0.1)
print(p1) 

# **Пример 3.**
#
# В задаче из примера 2 после первого детектора поставили такой же второй. \
# Пусть оба детектора показывают результат &laquo;b&raquo;: $b_1$ и $b_2$.
# Как при этом изменится вероятность ложноположительного результата?
# Вероятность ошибки должна уменьшиться, но насколько именно?
#
# Применим формулу Байеса для события $\{b_1 \cap b_2\}$:
# $$ \mathrm{P}(B|b_1 b_2) = \mathrm{P}(B) \dfrac{\mathrm{P}(b_1 b_2|B)}{\mathrm{P}(b_1 b_2)}. $$
#
# Обратим внимание, что события $b_1$ и $b_2$, не являясь независимыми сами по себе, являются независимыми для каждой из частиц по отдельности: $\mathrm{P}(b_1 b_2) \ne \mathrm{P}(b_1) \mathrm{P}(b_2)$, но $\mathrm{P}(b_1 b_2|B) = \mathrm{P}(b_1|B) \mathrm{P}(b_2|B)$.
# Поэтому
# $$ \mathrm{P}(B|b_1 b_2) = \mathrm{P}(B) \dfrac{\mathrm{P}(b_1|B) \mathrm{P}(b_2|B)}{\mathrm{P}(B)\mathrm{P}(b_1|B)\mathrm{P}(b_2|B) + \mathrm{P}(A)\mathrm{P}(b_1|A)\mathrm{P}(b_2|A)} = 0.05 \dfrac{0.9 \cdot 0.9}{0.05 \cdot 0.9 \cdot 0.9 + 0.95 \cdot 0.1 \cdot 0.1} = 0.81. $$

p2 = 0.05*0.9*0.9/(0.05*0.9*0.9 + 0.95*0.1*0.1)
print(p2) 

# ### Отношение шансов и отношение правдоподобия ###
#
# Рассмотрим две конкурирующие гипотезы $H_1$ и $H_2$.\
# *Отношение правдоподобия* &mdash; это вероятность некоторого факта $D$ при условии гипотезы $H_1$, делённая на вероятность того же факта при условии гипотезы $H_2$: $LR = \dfrac{\mathrm{P}(D|H_1)}{\mathrm{P}(D|H_2)}$.
#
# Отношение правдоподобия фактически сравнивает относительную поддержку, предоставляемую неким фактом (свидетельством, доказательством) для двух конкурирующих гипотез, например, означающих виновность и невиновность.
#
# *Шансы* на какое-то событие &mdash; это вероятность того, что оно произойдет, делённая на вероятность того, что оно не произойдет.
# Например, если мы бросаем игральную кость, то шансы на выпадение шестерки &mdash; 1 к 5.

# Вычислим шансы в эксперименте из **примера 2**:
# $$
#   \dfrac{\mathrm{P}(B|b)}{\mathrm{P}(A|b)} = \dfrac{\frac{\mathrm{P}(B)\mathrm{P}(b|B)}{\mathrm{P}(b)}} {\frac{\mathrm{P}(A)\mathrm{P}(b|A)}{\mathrm{P}(b)}} = \frac{\mathrm{P}(B)}{\mathrm{P}(A)} \cdot \dfrac{\mathrm{P}(b|B)}{\mathrm{P}(b|A)}. \tag{3}\label{eq:chances} 
# $$
#
# Множитель $\mathrm{P}(b)$ удачно сократился и формула \eqref{eq:chances} в итоге выражает апостериорные шансы гипотезы через её начальные шансы и отношение правдоподобия.
#
# $$
#   c_1 = \dfrac{\mathrm{P}(B|b)}{\mathrm{P}(A|b)} = \frac{0.05}{0.95} \cdot \dfrac{0.9}{0.1} = 0.05263 \cdot 9 = 0.474, \\
#   \mathrm{P}(B|b) = \dfrac{c_1}{1+c_1} = 0.321.
# $$

c1 = 0.05/0.95 * 0.9/0.1
print(c1)
print(c1/(1+c1))

# Продолжим с экспериментом из **примера 3**.
#
# Формулу ([3](#mjx-eqn-eq:chances)) можно применить ещё раз, тогда апостериорные шансы после первого факта станут априорными перед учётом второго факта (при условии его независимости).
#
# В итоге получаем красивый результат: при объединении всех этапов процесс эквивалентен *умножению независимых отношений правдоподобия* и формированию общего составного отношения правдоподобия.
# А апостериорные шансы равны произведению априорных шансов на общее отношение правдоподобия всех фактов.
#
# $$
#   c_2 = \dfrac{\mathrm{P}(B|b_1 b_2)}{\mathrm{P}(A|b_1 b_2)} = \dfrac{\mathrm{P}(B)}{\mathrm{P}(A)} \cdot \dfrac{\mathrm{P}(b_1|B)}{\mathrm{P}(b_1|A)} \cdot \dfrac{\mathrm{P}(b_2|B)}{\mathrm{P}(b_2|A)}
#   = \dfrac{0.05}{0.95} \cdot \frac{0.9}{0.1} \cdot \dfrac{0.9}{0.1} = 0.05263 \cdot 81 = 4.263.
# $$
#
# В итоге искомая условная вероятность равна
# $$ \mathrm{P}(B|b_1 b_2) = \dfrac{c_2}{1+c_2} = 0.81. $$

c2 = c1 * 0.9/0.1
print(c2)
print(c2/(1+c2))

# + [markdown] slideshow={"slide_type": "skip"}
# ---

# + [markdown] slideshow={"slide_type": "slide"}
# ## Источники ##
#
# 1. *Ширяев А.Н.* Вероятность &mdash; 1. &mdash; М.: МЦНМО, 2007. &mdash; 517 с.
# 1. *Чернова Н. И.* Теория вероятностей. Учебное пособие. &mdash; Новосибирск, 2007. &mdash; 160 с.
# 1. *Феллер В.* Введение в теорию вероятностей и её приложения. &mdash; М.: Мир, 1964. &mdash; 498 с.
# 1. *Шпигельхалтер Д.* Искусство статистики. Как находить ответы в данных. &mdash; М.: Манн, Иванов и Фербер, 2021. &mdash; 448 с.
# -


