# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:light
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.5.2
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# + [markdown] slideshow={"slide_type": "slide"}
# # Основные сведения из линейной алгебры &mdash; 1 #
# -

# ## Введение ##
#
# Что мы хотим вспомнить из линейной алгебры? Мы хотим уметь решать три основные задачи:
#
# 1. Найти $x$ в уравнении $Ax = b$;
# 1. Найти $x$ и $\lambda$ в уравнении $Ax = \lambda x$;
# 1. Найти $v$, $u$ и $\sigma$ в уравнении $Av = \sigma u$.
#
#
# Другие формулировки:
#
# 1. Можно ли вектор $b$ представить в виде линейной комбинации векторов матрицы $A$?
# 1. Вектор $Ax$ имеет то же направление, что и вектор $x$. Вдоль этого направления все сложные взаимодействия с матрицей $A$ чрезвычайно упрощаются. Вектор $A^2 x$ становится просто $\lambda^2 x$, матрица $e^{At}$ &mdash; $e^{\lambda t}$. Все действия становятся линейными.
# 1. Уравнение $Av = \sigma u$ похоже на предыдущее, но матрица $A$ больше не квадратная. Это сингулярное разложение.

# ---

# ## Умножение матриц (4 способа) ##
#
# Давайте начнём с умножения матриц.
# $$ A \cdot B = C $$
#
# 1. Строка на столбец
# 1. Столбец на строку
# 1. Столбец на столбец
# 1. Строка на строку
#
# Для начала введём обозначения. Вектор будем записывать в виде столбца и обозначать стрелочкой $\vec{a}$ или жирной буквой $\mathbf{a}$.
# Строку будем обозначать с помощью звёздочки $\vec{a}^*$ или $\mathbf{a}^*$:
# $$
#   \mathbf{a} =
#   \begin{pmatrix}
#      a_1    \\
#      \cdots \\
#      a_n    \\
#   \end{pmatrix},
#   \mathbf{a}^* = (a_1, \ldots, a_n).
# $$

# ### Способ 1: &laquo;строка на столбец&raquo; ###
#
# Это стандартный способ умножения матриц: $c_{ij} = \mathbf{a}_i^* \cdot \mathbf{b}_j$.
#
# **Пример 1.** Скалярное произведение векторов $\mathbf{a}$ и $\mathbf{b}$:
# $$ (\mathbf{a}, \mathbf{b}) = \mathbf{a}^\top \cdot \mathbf{b}. $$

# ### Способ 2: &laquo;столбец на строку&raquo; ###
#
# Существует другой способ умножения матриц.
# Произведение $AB$ равно *сумме произведений* всех столбцов матрицы $A$ на соотвествующие строки матрицы $B$.
# $$ A \cdot B = \sum_i \mathbf{a}_i \cdot \mathbf{b}_i^*. $$
#
# **Пример 2.**
# $$
#   \begin{pmatrix}
#      1 & 2 \\
#      0 & 2 \\
#   \end{pmatrix}
#   \cdot
#   \begin{pmatrix}
#      0 & 5 \\
#      1 & 1 \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#      1 \\
#      0 \\
#   \end{pmatrix}
#   \cdot
#   \begin{pmatrix}
#      0 & 5 \\
#   \end{pmatrix}
#   +
#   \begin{pmatrix}
#      2 \\
#      2 \\
#   \end{pmatrix}
#   \cdot
#   \begin{pmatrix}
#      1 & 1 \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#      0 & 5 \\
#      0 & 0 \\
#   \end{pmatrix}
#   +
#   \begin{pmatrix}
#      2 & 2 \\
#      2 & 2 \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#      2 & 7 \\
#      2 & 2 \\
#   \end{pmatrix}.
# $$

# ### Способ 3: &laquo;столбец на столбец&raquo; ###
#
# Посмотрим внимательно на то, как мы получили первый столбец результирующней матрицы.
# Он является суммой столбцов матрицы $A$ с коэффициентами из первого столбца матрицы $B$!
# То же самое можно сказать и про второй столбец.
# Таким образом, можно сформулировать следующее правило: \
# *$\mathbf{i}$-ый столбец результирующей матрицы есть сумма всех столбцов левой матрицы с коэффициентами из $\mathbf{i}$-ого столбца правой матрицы.*

# ### Способ 4: &laquo;строка на строку&raquo; ###
#
# Аналогичным образом можно вывести правило и для строк: \
# *$\mathbf{i}$-ая строка результирующей матрицы есть сумма всех строк правой матрицы с коэффициентами из $\mathbf{i}$-ой строки левой матрицы.*

# + [markdown] slideshow={"slide_type": "slide"}
# **Пример 3. Умножение матрицы на вектор**
#
# Рассмотрим умножение матрицы $A$ размером $m \times n$ на вектор: $A \mathbf{x}$.
#
# По определению произведение $A \mathbf{x}$ есть вектор, в котором на $i$-ом месте находится скалярное произведение $i$-ой *строки* на столбец $\mathbf{x}$:
# $$
#   A \mathbf{x} = 
#   \begin{pmatrix}
#     -\, \mathbf{a}_1^* \,- \\
#     \cdots \\
#     -\, \mathbf{a}_i^* \,- \\
#     \cdots \\
#     -\, \mathbf{a}_m^* \,- \\
#   \end{pmatrix}
#   \cdot \mathbf{x} = 
#   \begin{pmatrix}
#     \mathbf{a}_1^* \cdot \mathbf{x} \\
#     \cdots \\
#     \mathbf{a}_i^* \cdot \mathbf{x} \\
#     \cdots \\
#     \mathbf{a}_m^* \cdot \mathbf{x} \\
#   \end{pmatrix}.
# $$
#
# Но можно посмотреть на это иначе, как на произведение *столбцов* матрицы $A$ на элементы вектора $\mathbf{x}$:
# $$
#   A \mathbf{x} = 
#   \begin{pmatrix}
#      | & {} & | & {} & | \\
#      \mathbf{a}_1 & \cdots & \mathbf{a}_i & \cdots & \mathbf{a}_n \\
#      | & {} & | & {} & | \\
#   \end{pmatrix}
#   \begin{pmatrix}
#      x_1    \\
#      \cdots \\
#      x_i    \\
#      \cdots \\
#      x_m \\
#   \end{pmatrix}
#   = 
#   x_1 \mathbf{a}_1 + \dots + x_i \mathbf{a}_i + \dots + x_m \mathbf{a}_m.
# $$
# Таким образом, результирующий вектор есть *линейная комбинация* столбцов матрицы $A$ с коэффициентами из вектора $\mathbf{x}$.
# -

# **Пример 4. Умножение столбцов (строк) матрицы на скаляры**
#
# Чтобы каждый вектор матрицы $A$ умножить на скаляр $\lambda_i$, нужно умножить $A$ на матрицу $\Lambda = \mathrm{diag}(\lambda_i)$ *справа*:
# $$
#   \begin{pmatrix}
#     | & {} & | \\
#     \lambda_1 \mathbf{a}_1 & \cdots & \lambda_n \mathbf{a}_n \\
#     | & {} & | \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#     | & {} & | \\
#     \mathbf{a}_1 & \cdots & \mathbf{a}_n \\
#     | & {} & | \\
#   \end{pmatrix}
#   \begin{pmatrix}
#     \lambda_{1} & \ldots & 0         \\
#     \vdots      & \ddots & \vdots    \\
#     0           & \ldots & \lambda_n \\
#   \end{pmatrix}
#   = A \cdot \Lambda.
# $$
#
# Чтобы проделать то же самое со строками матрицы, её нужно умножить на $\Lambda$ *слева*:
# $$
#   \begin{pmatrix}
#     -\, \lambda_1 \mathbf{a}_1^* \,- \\
#     \cdots \\
#     -\, \lambda_m \mathbf{a}_m^* \,- \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#     \lambda_{1} & \ldots & 0         \\
#     \vdots      & \ddots & \vdots    \\
#     0           & \ldots & \lambda_n \\
#   \end{pmatrix}
#   \begin{pmatrix}
#     -\, \mathbf{a}_1^* \,- \\
#     \cdots \\
#     -\, \mathbf{a}_m^* \,- \\
#   \end{pmatrix}
#   = \Lambda \cdot A.
# $$

# **Пример 5. Умножение блочных матриц**
#
# Рассмотрим блочную матрицу следующего вида: 
# $$ A = \begin{pmatrix} A_1 \\ A_2 \\ \end{pmatrix}. $$
#
# 1. Формулу для $A A^\top$ получим по способу &laquo;строка на столбец&raquo;:
# $$
#   A A^\top = 
#   \begin{pmatrix}
#     A_1 \\
#     A_2 \\
#   \end{pmatrix}
#   \cdot
#   \begin{pmatrix}
#     A_1^\top & A_2^\top \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#     A_1 A_1^\top & A_1 A_2^\top \\
#     A_2 A_2^\top & A_2 A_2^\top \\
#   \end{pmatrix}
# $$
# 2. Для $A^\top A$ удобно применить способ &laquo;столбец на строку&raquo;:
# $$
#   A^\top A =
#   \begin{pmatrix}
#     A_1^\top & A_2^\top \\
#   \end{pmatrix}
#   \begin{pmatrix}
#     A_1 \\
#     A_2 \\
#   \end{pmatrix}
#   = A_1^\top A_1 + A_2^\top A_2
# $$

# ---

# ### Линейная оболочка, размерность пространства, ранг матрицы ###
#
# Посмотрим ещё раз на задачу $A \mathbf{x} = \mathbf{b}$. \
# Теперь её можно переформулировать так: ответить, можно ли столбец $\mathbf{b}$ представить в виде линейной комбинации столбцов матрицы $A$.
#
# Поясним на примере.
# Пусть
# $$
#   A = 
#   \begin{pmatrix}
#      1 & 2 & 3 \\
#      2 & 1 & 3 \\
#      3 & 1 & 4 \\
#   \end{pmatrix}.
# $$
# Что мы можем сказать о линейной оболочке её столбцов? Что это за пространство? Какой размерности?

# **Определение 1.** Рангом матрицы $A$ с $n$ строк и $m$ столбцов называется максимальное число линейно независимых столбцов (строк).
#
# > В матрице $A$ первые два вектора линейно независимы.
# > Попробуем взять их в качестве базиса и разложить по ним третий.
# > Запишем это в матричном виде, пользуясь правилом умножения &laquo;столбец на столбец&raquo;.
# > Мы получлили скелетное разложение матрицы.

# **Определение 2.** *Скелетным разложением* матрицы $A$ размеров $m \times n$ и ранга $r>0$ называется разложение вида $A = CR$, где матрицы $C$ и $R$ имеют размеры соттвественно $m \times r$ и $r \times n$.
# Другое название скелетного разложения &mdash; ранговая факторизация.
#
# Так как ранг произведения не превосходит рангов сомножителей, а ранги $C$ и $R$ не могут быть больше $r$, то они равны $r$.
#
# $$
#   A = 
#   \begin{pmatrix}
#      1 & 2 & 3 \\
#      2 & 1 & 3 \\
#      3 & 1 & 4 \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#      1 & 2 \\
#      2 & 1 \\
#      3 & 1 \\
#   \end{pmatrix}
#   \cdot
#   \begin{pmatrix}
#      1 & 0 & 1 \\
#      0 & 1 & 1 \\
#   \end{pmatrix}
#   = C \cdot R
# $$
#
# Здесь $C$ &mdash; базисные столбцы, $R$ &mdash; базисные строки.
# Это разложение доказывает теорему: ранг матрицы по столбцам (количество независимых столбцов) равен рангу матрицы по строкам (количество независимых строк).

# **Дополнительно**
#
# Существует другой вариант скелетного разложения: $A = CMR$.
# В этом случае матрица $С$, как и ранее, состоит из $r$ независимых столбцов матрицы $A$, матрица $R$ теперь состоит из $r$ независимых строк матрицы $A$, а матрица $M$ размером $r \times r$ называется смешанной матрицей (mixing matrix).
# Для $M$ можно получить следующую формулу:
# $$
#   A = CMR \\
#   C^\top A R^\top = C^\top C M R R^\top \\
#   M = (C^\top C)^{-1} (C^\top A R^\top) (R R^\top)^{-1}.
# $$
#
# Обратим внимание на используемый приём &mdash; домножение прямоугольной матрицы на транспонированную.
# Полученную квадратную матрицу можно домножать на обратную (&laquo;делить на матрицу&raquo;).
# Этот приме можно использовать далеко не всегда.

# ***Разложение матрицы на сумму матриц ранга 1.***
#
# Применяем умножение &laquo;столбец на строку&raquo;:
# $$
#   A = 
#   \begin{pmatrix}
#      1 & 2 & 3 \\
#      2 & 1 & 3 \\
#      3 & 1 & 4 \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#      1 & 2 \\
#      2 & 1 \\
#      3 & 1 \\
#   \end{pmatrix}
#   \cdot
#   \begin{pmatrix}
#      1 & 0 & 1 \\
#      0 & 1 & 1 \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#      1 & 0 & 1 \\
#      2 & 0 & 2 \\
#      3 & 0 & 3 \\
#   \end{pmatrix}
#   +
#   \begin{pmatrix}
#      0 & 2 & 2 \\
#      0 & 1 & 1 \\
#      0 & 1 & 1 \\
#   \end{pmatrix}.
# $$

# ---

# Вернемся к СЛАУ.
# Теорема Фредгольма в виде пространства столбцов, пространства строк и в виде ядро-образ.
#
# **&laquo;Большая картина линейной алгебры&raquo;**

# Разложения матриц.
#
# 1. LU
#
# 1. Приведение матрицы к диагональному виду.
#
# Ортогональные матрицы (сложим ортонормированные вектора). Пример: вращение, отражение. \
# Симметричные матрицы. Пример: ортогональная проекция, отражение (симметричная и ортогональная одновременно?).
#
# 1. Спектральное разложение симметричной матрицы.
#
# 1. QR, обобщение

# ## Замечательные матрицы ##
#
# 1. Симметричная матрица
# 1. Симметричная положительно определённая матрица
# 1. Ортогональная матрица
#
# **Примеры**: $A^\top A$, матрица ортогональной проекции, матрицы поворота и симметрии.

# ### Матрица ортогональной проекции ###
#
# Пусть заданы вектор $\mathbf{b}$ из $\mathbb{R}_m$ и набор векторов $\mathbf{a}_i$, образующих базис в $\mathbb{R}_n$ ($n<m$).
#
# Требуется найти ортогональную проекцию вектора $\mathbf{b}$ на линейную оболочку векторов $\mathbf{a}_i$.
#
# Искомый вектор является линейной комбинацией базисных векторов $\mathbf{a}_i$ с неизвестными коэффициентами $x_i$.
# Запишем это в виде произведения матрицы $A$, столбцы которой являются векторами $\mathbf{a}_i$, на неизвестный вектор $\mathbf{x}$: $A\mathbf{x}$.
# Мы ищем ортогональную проекцию на пространство столбцов матрицы $A$, поэтому вектор $A\mathbf{x} - \mathbf{b}$ должен быть ортогонален *любому* вектору $A\mathbf{y}$.
# Запишем это через скалярное произведение:
# $$
#   (A \mathbf{y})^\top(A\mathbf{x} - \mathbf{b}) = \mathbf{y}^\top (A^\top A \mathbf{x} - A^\top \mathbf{b}) = 0.
# $$
#
# Это српаведливо для произвольного вектора $\mathbf{y}$, откуда следует, что
# $$
#   A^\top A \mathbf{x} = A^\top \mathbf{b}.
# $$
#
# Ранг матрицы $A^\top A$ равен рангу $A$, а столбцы матрицы $A$ линейно независимы, следовательно матрица $A^\top A$ обратима.
# Отсюда находим выражение для вектора коэффициентов проекции и сам вектор проекции $\mathbf{p} = A\mathbf{x}$
# $$
#   \mathbf{x} = (A^\top A)^{-1} A^\top \mathbf{b}, \
#   \mathbf{p} = A (A^\top A)^{-1} A^\top \mathbf{b}.
# $$
#
# Матрица $P = A (A^\top A)^{-1} A^\top \mathbf{b}$, осуществляющая проекцию, называется *матрицей ортогонального проектирования*.
# Матрица ортопроектирования обладает двумя основными свойствами:
#
# 1. $P^2 = P$ &mdash; характеристическое свойство всех проекторов,
# 1. $P^\top = P$ &mdash; отличительное свойство ортогонального проектора.

# ---

# ## Разложения матриц##
#
# Рассмотрим пять замечательных разложений матриц
#
# 1. $A = LU$
# 1. $A = QR$
# 1. $A = X \Lambda X^{-1}$
# 1. $S = Q \Lambda Q^\top$
# 1. $A = U \Sigma V^\top$

# ### $\mathbf{LU}$-разложение ###
#
# > Ограничения: матрица $A$ &mdash; квадратная и невырожденная

# ---

# ### $\mathbf{QR}$-разложение ###
#
# Большую роль в численных методах играет разложение *квадратной матрицы* $A$ на ортогональную матрицу $Q$ и верхнетреугольную матрицу $R$.
# $$
#   A = QR.
# $$
#
# **Предложение 1.** Любая квадратная матрица $A$ может быть разложена в произведение $QR$. \
# **Предложение 2.** Если матрица $A$ невырождена, то её $QR$-разложение, в котором диагональные элементы $R$ положительны, единственно. \
# **Предложение 3.** $QR$-разложение тесно связано с процессом ортогонализации Грама &mdash; Шмидта. Действительно, $AU = Q$ равносильно $QR$-разложению с $R = U^{-1}$.
#
#
#
#
# **Пример.** Рассмотрим систему линейных уравнений $A\mathbf{x} = \mathbf{b}$. Используя $QR$-разложение матрицы $A$, получим
#
# $$
#   QR \mathbf{x} = \mathbf{b}, \\
#   R \mathbf{x} = Q^\top \mathbf{b}.
# $$
#
# И в случе невырожденной $R$
# $$
#   \mathbf{x} = R^{-1}Q^\top \mathbf{b}.
# $$

# ### $\mathbf{QR}$-разложение прямоугольных матриц ###
#
# Произвольную матрицу размером $m \times n$ можно представить в виде разложения
# $$
#   A = QR,
# $$
# где $Q$ &mdash; ортогональная матрица порядка $m$, а $R$ &mdash; матрица размеров $m \times n$, элементы $r_{ij}$ которой удовлетворяют условию $r_{ij}=0$ при $i>j$.
# Такое разложение назовём $Qr$-разложением, чтобы подчеркнуть, что матрица $R$, вообще говоря, не является квадратной.
#
# Второе обобщение $QR$-разложения можно получить, применяя метод ортогонализации Грама &mdash; Шмидта.
# Теперь матрица $Q$ размеров $m \times n$ может рассматриваться как совокупность $n$ столбцов из некоторой ортогональной матрицы порядка $m$, а $R$ &mdash; квадратная верхняя треугольная матрица порядка $n$.
# Такое разложение будем называть $qR$-разложением.







import numpy as np
from numpy import linalg as LA
from scipy import linalg as LAS

# +
np.random.seed(1)
A = np.random.randint(0, 10, (3,3))
display(A)

P, W, G = LAS.lu(A)

# display(P)

display(W)
# display(LA.inv(L))

display(G)
# display(LA.inv(U))

# +
np.random.seed(12345)

D = np.diag((15, 10, 5))
B = np.random.randint(0, 10, (3,3))
# print(B)
A = B @ D @ LA.inv(B)
print(LA.eigvals(A))

A1 = A
for i in range(10):
    Q, R = LA.qr(A1)
    A1 = R@Q
    print(np.diag(A1))
# -









import numpy as np
from numpy import linalg as LA

A = np.array([[1,2,3],[2,1,3],[3,1,4]])
C = np.array([[1,2],[2,1],[3,1]])
R = np.array([[1,2,3],[2,1,3]])

M = LA.inv(C.T@C) @ (C.T@A@R.T) @ LA.inv(R@R.T)
print(M)
B = C@M@R
print(B)

# + [markdown] slideshow={"slide_type": "skip"}
# ---

# + [markdown] slideshow={"slide_type": "slide"}
# ## Литература ##
#
# 1. G. Strang. Linear algebra and learning from data. Wellesley-Cambridge Press, 2019. 432 p.
# 1. Д.В. Беклемишев. Дополнительные главы линейной алгебры. М.: Наука, 1983. 336 с.
# -


