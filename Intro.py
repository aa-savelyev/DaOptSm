# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:light
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.5.2
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# # Введение #
# **

# > ***Дисклеймер.***
# > Альтернативным названием данного курса является &laquo;Методы машинного обучения и их применение в прикладных задачах аэродинамики&raquo;.
# Моя цель дать краткий обзор тех методов машинного обучения, которые мы (Отдел вычислительной аэродинамики Отделения аэродинамики силовых установок ЦАГИ) применяем в задачах аэродинамического проектирования, и привести несколько примеров таких задач.
# > В основе этого курса лежит достаточно много литературы (несколько десятков источников). Многие части текста взяты из этой литературы напрямую или переведены с английского. Фактически, в настоящий момент данный курс является компиляцией материалов из различных источников с добавлением кода на Питоне и примеров из практики.
# > У меня не было физической возможности спросить у всех авторов разрешение использовать их материалы, поэтому я делаю это без их разрешения. Я искренне надеюсь, что они не будут на меня не в обиде за это. Оправданием мне может служить тот факт, что я делаю это с целью преподавания.
#
# В основе методов машинного обучения лежат линейная алгебра, теория вероятностей и методы оптимизации.
# Мы начнём с краткого введения в каждую из этих дисциплин и посвятим этому добрую половину нашего курса.
#
# Но в самом начале будет полезно рассматреть типичную постановку задачи машинного обучения.

# ## Машинное обучение и обучение по прецендентам ##
#
# **Машинное обучение** (*wikipedia*) — класс методов искусственного интеллекта, характерной чертой которых является не прямое решение задачи, а обучение в процессе применения решений множества сходных задач. Для построения таких методов используются средства математической статистики, численных методов, методов оптимизации, теории вероятностей, теории графов, различные техники работы с данными в цифровой форме.
#
# Различают два типа обучения:
#
#  - *Обучение по прецедентам*, или индуктивное обучение, основано на выявлении эмпирических закономерностей в данных.
#  - *Дедуктивное обучение* предполагает формализацию знаний экспертов и их перенос в компьютер в виде базы знаний.
#
# Дедуктивное обучение принято относить к области экспертных систем, поэтому термины **машинное обучение и обучение по прецедентам можно считать синонимами**.

# ## Постановка задачи ##
#
# **Задача (кратко)**: построить функцию корректно описывающую обучающие данные и обобщающую их на неизвестные тестовые данные.
#
# Теперь подробнее.
#
# Пусть задано множество объектов $X$ и множество допустимы ответов $Y$. Мы предполагаем существование зависимости $y:X \rightarrow Y$. При этом значения функции $y_i = y(x_i)$ известны только на конечном подмножестве объектов $\{x_1, \ldots, x_l\} \subset X$.
# Пары &laquo;объект&ndash;ответ&raquo; $(x_i, y_i)$ называются *прецендентами*, а совокупность пар $X^l = (x_i, y_i)_{i=1}^l$ &mdash; *обучающей выборкой*.
#
# *Признак* (feature) $f$ объекта $x$ &mdash; это результат измерения некоторой характеристики объекта.
#
# Пусть имеется набор признаков $f_1, \ldots, f_n$.
# Вектор $(f_1, \ldots, f_n)$ называют признаковым описанием объекта $x \in X$. В дальнейшем мы не будем различать объекты из $X$ и их признаковые описания.
# Совокупность признаковых описаний всех объектов выборки $X_l$, записанную в виде таблицы размера $l \times n$, называют матрицей объектов&ndash;признаков:
# $$
#   \mathbf{F} = 
#   \begin{pmatrix}
#     f_1(x_1) & \ldots & f_n(x_1) \\
#     \ldots   & \ldots & \ldots   \\
#     f_1(x_l) & \ldots & f_n(x_l) \\
#   \end{pmatrix}.
# $$
#
# Матрица объектов–признаков является стандартным и наиболее распространённым способом представления исходных данных в прикладных задачах.
#
# **Задача**: построить функцию $a: X \rightarrow Y$, аппроксимирующую целевую зависимость $y$. Функция должна корректно описывать обучающие данные и должна быть успешно применима для неизвестных тестовых данных.

# Простейшая функция обучения была бы линейной: w = Av. Элементы в матрице A - это веса, которые необходимо изучить: не так уж сложно. Часто функция также изучает вектор смещения b, так что F (v) = Av + b. Эта функция «аффинная».
# Аффинные функции можно быстро изучить, но сами по себе они слишком просты.
#
# Точнее, линейность - очень ограничивающее требование.   






