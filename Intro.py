# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:light
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.5.2
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# # Введение #
# **

# Альтернативным названием данного курса является &laquo;Методы машинного обучения и их применение в прикладных задачах аэродинамики&raquo;.
# Моя цель дать краткий обзор тех методов машинного обучения, которые мы (Отдел вычислительной аэродинамики Отделения аэродинамики силовых установок ЦАГИ) применяем в задачах аэродинамического проектирования, и привести несколько примеров таких задач.
#
# В основе этого курса лежит достаточно много литературы (несколько десятков источников). Многие части текста взяты из этой литературы напрямую или переведены с английского. Фактически, в настоящий момент данный курс является компиляцией материалов из различных источников с добавлением кода на Питоне и примеров из практики. Основными источниками явлются
#
# 1. Воронцов К.В. [Математические методы обучения по прецендентам (теория обучения машин)](http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf). 141 c.
# 1. Strang G. Linear algebra and learning from data. Wellesley-Cambridge Press, 2019. 432 p.
# 1. Ширяев А.Н. Вероятность &mdash; 1. М.: МЦНМО, 2007. 517 с.
# 1. Материалы авторов [P. Roelants](https://peterroelants.github.io/) и [M. Krasser ](http://krasserm.github.io/).
#
#
# Должен признаться, что я не спрашивал у авторов разрешение использовать их материалы и делаю это без их разрешения. Я искренне надеюсь, что они не будут в обиде на меня за это. Оправданием мне может служить тот факт, что я делаю это с целью преподавания.
#
# Курсы лекций, находящиеся в открытом доступе:
#
# 1. [Линейная алгебра](https://www.youtube.com/watch?v=WNl10xl1QT8&list=PLthfp5exSWEqSRXkZgMMzTSXL_WwMV9wK), к.ф.-м.н. Павел Александрович Кожевников, МФТИ
# 2. [Теория вероятностей](https://www.youtube.com/watch?v=Q3h9P7lhpNc&list=PLyBWNG-pZKx7kLBRcNW3HXG05BDUrTQVr&index=1), д.ф.-м.н. Максим Евгеньевич Широков, МФТИ
# 3. [Машинное обучение](https://www.youtube.com/watch?v=SZkrxWhI5qM&list=PLJOzdkh8T5krxc4HsHbB8g8f0hu7973fK&index=1), д.ф.-м.н. Константин Вячеславович Воронцов, ШАД (Яндекс)
# 4. [Matrix Methods in Data Analysis, Signal Processing, and Machine Learning](https://www.youtube.com/watch?v=Cx5Z-OslNWE&list=PLUl4u3cNGP63oMNUHXqIUcrkS2PivhN3k), prof. Gilbert Strang, MIT

# В основе методов машинного обучения лежат линейная алгебра, теория вероятностей и методы оптимизации.
# Мы начнём с краткого введения в каждую из этих дисциплин и посвятим этому добрую половину нашего курса.
#
# Но в самом начале будет полезно рассматреть типичную постановку задачи машинного обучения.

# ## Машинное обучение и обучение по прецендентам ##
#
# **Машинное обучение** (*wikipedia*) — класс методов искусственного интеллекта, характерной чертой которых является не прямое решение задачи, а обучение в процессе применения решений множества сходных задач. Для построения таких методов используются средства математической статистики, численных методов, методов оптимизации, теории вероятностей, теории графов, различные техники работы с данными в цифровой форме.
#
# Различают два типа обучения:
#
# - *Обучение по прецедентам*, или индуктивное обучение, основано на выявлении эмпирических закономерностей в данных.
# - *Дедуктивное обучение* предполагает формализацию знаний экспертов и их перенос в компьютер в виде базы знаний.
#
# Дедуктивное обучение принято относить к области экспертных систем, поэтому термины **машинное обучение и обучение по прецедентам можно считать синонимами**.

# ## Постановка задачи ##
#
# **Задача (кратко)**: построить функцию корректно описывающую обучающие данные и обобщающую их на неизвестные (тестовые) данные.
#
# Теперь подробнее.
#
# Пусть задано множество объектов $X$ и множество допустимы ответов $Y$. Мы предполагаем существование зависимости $y:X \rightarrow Y$. При этом значения функции $y_i = y(x_i)$ известны только на конечном подмножестве объектов $\{x_1, \ldots, x_l\} \subset X$.
# Пары &laquo;объект&ndash;ответ&raquo; $(x_i, y_i)$ называются *прецендентами*, а совокупность пар $X^l = (x_i, y_i)_{i=1}^l$ &mdash; *обучающей выборкой*.
#
# *Признак* (feature) $f$ объекта $x$ &mdash; это результат измерения некоторой характеристики объекта.
#
# Пусть имеется набор признаков $f_1, \ldots, f_n$.
# Вектор $(f_1, \ldots, f_n)$ называют признаковым описанием объекта $x \in X$. В дальнейшем мы не будем различать объекты из $X$ и их признаковые описания.
# Совокупность признаковых описаний всех объектов выборки $X_l$, записанную в виде таблицы размера $l \times n$, называют матрицей объектов&ndash;признаков:
# $$
#   \mathbf{F} = 
#   \begin{pmatrix}
#     f_1(x_1) & \ldots & f_n(x_1) \\
#     \ldots   & \ldots & \ldots   \\
#     f_1(x_l) & \ldots & f_n(x_l) \\
#   \end{pmatrix}.
# $$
#
# Матрица объектов–признаков является стандартным и наиболее распространённым способом представления исходных данных в прикладных задачах.
#
# **Задача**: построить функцию $a: X \rightarrow Y$, аппроксимирующую неизвестную целевую зависимость $y$. Функция должна корректно описывать обучающие данные и должна быть успешно применима для неизвестных тестовых данных.

# Простейшим выбором является линейная функция: $y = Ax$.
# Элементы матрицы A &mdash; это веса, которые необходимо найти: не так уж сложно.
# С линейными функциями приятно работать, они просты, пожалуй, даже слишком просты. Линейность &mdash; очень ограничивающее требование.   

# ## Содержание курса ##
#
# 1. Линейная алгебра
# 1. Теория вероятностей
# 1. Методы оптимизации
# 1. Гауссовы процессы

# ## Литература ##
#
# 1. Воронцов К.В. [Математические методы обучения по прецендентам (теория обучения машин)](http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf). 141 c.
# 1. Strang G. [Linear algebra and learning from data](ссылка). Wellesley-Cambridge Press, 2019. 432 p.
#


