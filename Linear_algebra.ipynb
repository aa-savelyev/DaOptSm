{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Необходимые сведения из линейной алгебры &mdash; 1 #\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение ##\n",
    "\n",
    "Что мы хотим вспомнить из линейной алгебры? Мы хотим уметь решать пять базовых задач:\n",
    "\n",
    "1. Найти $x$ в уравнении $Ax = b$;\n",
    "1. Найти $x$ и $\\lambda$ в уравнении $Ax = \\lambda x$;\n",
    "1. Найти $v$, $u$ и $\\sigma$ в уравнении $Av = \\sigma u$;\n",
    "1. Найти минимум выражения $\\dfrac{\\lVert Ax \\rVert^2}{\\lVert x \\rVert^2}$;\n",
    "1. Найти разложение матрицы $A$.\n",
    "\n",
    "\n",
    "1. Можно ли вектор $b$ представить в виде линейной комбинации векторов матрицы $A$?\n",
    "1. Вектор $Ax$ имеет то же направление, что и вектор $x$. Вдоль этого направления все сложные взаимодействия с матрицей $A$ чрезвычайно упрощаются. Вектор $A^2 x$ становится просто $\\lambda^2 x$, матрица $e^{At}$ &mdash; $e^{\\lambda t}$. Все действия становятся линейными.\n",
    "1. Уравнение $Av = \\sigma u$ похоже на предыдущее. Но матрица $A$ больше не квадратная. Это сингулярное разложение\n",
    "1. Минимизация и факторизация являются фундаментальными прикладными задачами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Умножение матриц ##\n",
    "\n",
    "Давайте начнём с умножения матриц.\n",
    "\n",
    "### Умножение матрицы на вектор ###\n",
    "\n",
    "Для начала введём обозначения. Вектор будем записывать в виде столбца и обозначать вектором $\\vec{a}$ или жирной буквой $\\mathbf{a}$.\n",
    "С помощью $\\vec{a}^\\top$ или $\\mathbf{a}^\\top$ будем обозначать транспонировнный столбец, т.е. строку:\n",
    "$$\n",
    "  \\mathbf{a} =\n",
    "  \\begin{pmatrix}\n",
    "     a_1    \\\\\n",
    "     \\cdots \\\\\n",
    "     a_n    \\\\\n",
    "  \\end{pmatrix},\n",
    "  \\mathbf{a}^\\top = (a_1, \\ldots, a_n).\n",
    "$$\n",
    "\n",
    "Рассмотрим умножение матрицы $A$ размером $l \\times n$ на вектор: $A \\mathbf{x}$.\n",
    "\n",
    "По определению произведение $A \\mathbf{x}$ есть вектор, в котором на $i$-ом месте находится скалярное произведение $i$-ой *строки* на столбец $\\mathbf{x}$:\n",
    "$$\n",
    "  A \\mathbf{x} = \n",
    "  \\begin{pmatrix}\n",
    "    -\\, \\mathbf{a}_1^\\top \\,- \\\\\n",
    "    \\cdots \\\\\n",
    "    -\\, \\mathbf{a}_i^\\top \\,- \\\\\n",
    "    \\cdots \\\\\n",
    "    -\\, \\mathbf{a}_m^\\top \\,- \\\\\n",
    "  \\end{pmatrix}\n",
    "  \\cdot \\mathbf{x} = \n",
    "  \\begin{pmatrix}\n",
    "    \\mathbf{a}_1^\\top \\cdot \\mathbf{x} \\\\\n",
    "    \\cdots \\\\\n",
    "    \\mathbf{a}_i^\\top \\cdot \\mathbf{x} \\\\\n",
    "    \\cdots \\\\\n",
    "    \\mathbf{a}_m^\\top \\cdot \\mathbf{x} \\\\\n",
    "  \\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Но можно посмотреть на это иначе, как на произведение *столбцов* матрицы $A$ на элементы вектора $\\mathbf{x}$:\n",
    "$$\n",
    "  A \\mathbf{x} = \n",
    "  \\begin{pmatrix}\n",
    "     | & {} & | & {} & | \\\\\n",
    "     \\mathbf{a}_1 & \\cdots & \\mathbf{a}_i & \\cdots & \\mathbf{a}_n \\\\\n",
    "     | & {} & | & {} & | \\\\\n",
    "  \\end{pmatrix}\n",
    "  \\begin{pmatrix}\n",
    "     x_1    \\\\\n",
    "     \\cdots \\\\\n",
    "     x_i    \\\\\n",
    "     \\cdots \\\\\n",
    "     x_m \\\\\n",
    "  \\end{pmatrix}\n",
    "  = \n",
    "  x_1 \\mathbf{a}_1 + \\dots + x_i \\mathbf{a}_i + \\dots + x_m \\mathbf{a}_m.\n",
    "$$\n",
    "Таким образом, результирующий вектор есть *линейная комбинация* столбцов матрицы $A$ с коэффициентами из вектора $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная оболочка, размерность пространства, ранг матрицы ###\n",
    "\n",
    "Посмтрим ещё раз на задачу № 1 из списка выше: $A \\mathbf{x} = \\mathbf{b}$.\n",
    "Теперь её можно переформулировать так: ответить, можно ли столбец $\\mathbf{b}$ представить в виде линейной комбинации столбцов матрицы $A$.\n",
    "\n",
    "Поясним на примере.\n",
    "Пусть\n",
    "$$\n",
    "  A = \n",
    "  \\begin{pmatrix}\n",
    "     1 & 2 & 3 \\\\\n",
    "     2 & 1 & 3 \\\\\n",
    "     3 & 1 & 4 \\\\\n",
    "  \\end{pmatrix}\n",
    "$$\n",
    "Что мы можем сказать о линейной оболочке её столбцов? Что это за пространство? Какой размерности?\n",
    "\n",
    "**Определение 1.** Рангом матрицы $A$ с $n$ строк и $m$ столбцов называется максимальное число линейно независимых столбцов (строк).\n",
    "\n",
    "**Определение 2.** *Скелетным разложением* матрицы $A$ размеров $m \\times n$ и ранга $r>0$ называется разложение вида $A = CR$, где матрицы $C$ и $R$ имеют размеры соттвественно $m \\times r$ и $r \\times n$.\n",
    "\n",
    "Так как ранг произведения не превосходит рангов сомножителей, а ранги $C$ и $R$ не могут быть больше $r$, то они равны $r$.\n",
    "\n",
    "$$\n",
    "  A = \n",
    "  \\begin{pmatrix}\n",
    "     1 & 2 & 3 \\\\\n",
    "     2 & 1 & 3 \\\\\n",
    "     3 & 1 & 4 \\\\\n",
    "  \\end{pmatrix}\n",
    "  =\n",
    "  \\begin{pmatrix}\n",
    "     1 & 2 \\\\\n",
    "     2 & 1 \\\\\n",
    "     3 & 1 \\\\\n",
    "  \\end{pmatrix}\n",
    "  \\cdot\n",
    "  \\begin{pmatrix}\n",
    "     1 & 0 & 1 \\\\\n",
    "     0 & 1 & 1 \\\\\n",
    "  \\end{pmatrix}\n",
    "  = C \\cdot R.\n",
    "$$\n",
    "\n",
    "$C$ &mdash; базисные столбцы, $R$ &mdash; базисные строки.\n",
    "Это разложение доказывает теорему: ранг матрицы по столбцам (количество независимых столбцов) равен рангу матрицы по строкам (количество независимых строк)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует другой вариант скелетного разложения: $A = CMR$.\n",
    "В этом случае матрица $С$, как и ранее, состоит из $r$ независимых столбцов матрицы $A$, матрица $R$ теперь состоит из $r$ независимых строк матрицы $A$, а матрица $M$ размером $r \\times r$ называется смешанной матрицей (mixing matrix).\n",
    "Для $M$ можно получить следующую формулу:\n",
    "$$\n",
    "  A = CMR \\\\\n",
    "  C^\\top A R^\\top = C^\\top C M R R^\\top \\\\\n",
    "  M = (C^\\top C)^{-1} (C^\\top A R^\\top) (R R^\\top)^{-1}.\n",
    "$$\n",
    "\n",
    "Обратим внимание на используемый приём &mdash; домножение прямоугольной матрицы на транспонированную. Полученную квадратную матрицу (в случае если она невырожденная) можно уже домножать на обратную (&laquo;делить на матрицу&raquo;)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Разложение матрицы на сумму матриц ранга 1.***\n",
    "\n",
    "Применяем умножение &laquo;столбец на строку&raquo;:\n",
    "$$\n",
    "  A = \n",
    "  \\begin{pmatrix}\n",
    "     1 & 2 & 3 \\\\\n",
    "     2 & 1 & 3 \\\\\n",
    "     3 & 1 & 4 \\\\\n",
    "  \\end{pmatrix}\n",
    "  =\n",
    "  \\begin{pmatrix}\n",
    "     1 & 2 \\\\\n",
    "     2 & 1 \\\\\n",
    "     3 & 1 \\\\\n",
    "  \\end{pmatrix}\n",
    "  \\cdot\n",
    "  \\begin{pmatrix}\n",
    "     1 & 0 & 1 \\\\\n",
    "     0 & 1 & 1 \\\\\n",
    "  \\end{pmatrix}\n",
    "  =\n",
    "  \\begin{pmatrix}\n",
    "     1 & 0 & 1 \\\\\n",
    "     2 & 0 & 2 \\\\\n",
    "     3 & 0 & 3 \\\\\n",
    "  \\end{pmatrix}\n",
    "  +\n",
    "  \\begin{pmatrix}\n",
    "     0 & 2 & 2 \\\\\n",
    "     0 & 1 & 1 \\\\\n",
    "     0 & 1 & 1 \\\\\n",
    "  \\end{pmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Замечательные матрицы ##\n",
    "\n",
    "1. Симметричная матрица\n",
    "1. Симметричная положительно определённая матрица\n",
    "1. Ортогональная матрица\n",
    "\n",
    "**Примеры**: $A^\\top A$, матрица ортогональной проекции, матрицы поворота и симметрии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица ортогональной проекции ###\n",
    "\n",
    "Пусть заданы вектор $\\mathbf{b}$ из $\\mathbb{R}_m$ и набор векторов $\\mathbf{a}_i$, образующих базис в $\\mathbb{R}_n$ ($n<m$).\n",
    "\n",
    "Требуется найти ортогональную проекцию вектора $\\mathbf{b}$ на линейную оболочку векторов $\\mathbf{a}_i$.\n",
    "\n",
    "Искомый вектор является линейной комбинацией базисных векторов $\\mathbf{a}_i$ с неизвестными коэффициентами $x_i$.\n",
    "Запишем это в виде произведения матрицы $A$, столбцы которой являются векторами $\\mathbf{a}_i$, на неизвестный вектор $\\mathbf{x}$: $A\\mathbf{x}$.\n",
    "Мы ищем ортогональную проекцию на пространство столбцов матрицы $A$, поэтому вектор $A\\mathbf{x} - \\mathbf{b}$ должен быть ортогонален *любому* вектору $A\\mathbf{y}$.\n",
    "Запишем это через скалярное произведение:\n",
    "$$\n",
    "  (A \\mathbf{y})^\\top(A\\mathbf{x} - \\mathbf{b}) = \\mathbf{y}^\\top (A^\\top A \\mathbf{x} - A^\\top \\mathbf{b}) = 0.\n",
    "$$\n",
    "\n",
    "Это српаведливо для произвольного вектора $\\mathbf{y}$, откуда следует, что\n",
    "$$\n",
    "  A^\\top A \\mathbf{x} = A^\\top \\mathbf{b}.\n",
    "$$\n",
    "\n",
    "Ранг матрицы $A^\\top A$ равен рангу $A$, а столбцы матрицы $A$ линейно независимы, следовательно матрица $A^\\top A$ обратима.\n",
    "Отсюда находим выражение для вектора коэффициентов проекции и сам вектор проекции $\\mathbf{p} = A\\mathbf{x}$\n",
    "$$\n",
    "  \\mathbf{x} = (A^\\top A)^{-1} A^\\top \\mathbf{b}, \\\n",
    "  \\mathbf{p} = A (A^\\top A)^{-1} A^\\top \\mathbf{b}.\n",
    "$$\n",
    "\n",
    "Матрица $P = A (A^\\top A)^{-1} A^\\top \\mathbf{b}$, осуществляющая проекцию, называется *матрицей ортогонального проектирования*.\n",
    "Матрица ортопроектирования обладает двумя основными свойствами:\n",
    "\n",
    "1. $P^2 = P$ &mdash; характеристическое свойство всех проекторов,\n",
    "1. $P^\\top = P$ &mdash; отличительное свойство ортогонального проектора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разложения матриц##\n",
    "\n",
    "Рассмотрим пять замечательных разложений матриц\n",
    "\n",
    "1. $A = LU$\n",
    "1. $A = QR$\n",
    "1. $A = X \\Lambda X^{-1}$\n",
    "1. $S = Q \\Lambda Q^\\top$\n",
    "1. $A = U \\Sigma V^\\top$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. $\\mathbf{LU}$-разложение ###\n",
    "\n",
    "**TODO** Связь с Гауссом\n",
    "\n",
    "**Определение.** $LU$-разложением матрицы $A$ называется разложение матрицы $A$ в произведение $LU$ невырожденной нижней треугольной матрицы $L$ и верхней треугольной матрицы $U$ с единицами на главной диагонали.\n",
    "\n",
    "**Теорема (критерий существования).** $LU$-разложение матрицы $A$ существует тогда и только тогда, когда все главные миноры матрицы $A$ отличны от нуля. Если $LU$-разложение существует, то оно единственно.\n",
    "\n",
    "**Замечание.** Единственным является разложение на такие треугольные множители, что у второго из них на главной диагонали стоят единицы. Вообще же существует много треугольних разложений, в частности такое, в котором единицы находятся на главной диагонли у первого сомножителя.\n",
    "\n",
    "**Замечание.** $LU$-разложение можно рассматривать, как матричную форму записи метода исключения Гаусса.\n",
    "\n",
    "Матрицу $L$ можно представить как произведение матрицы $L_1$, имеющей единицы на главной диагонли, и диагональной матрицы $D$. Тогда мы получим\n",
    "**Предложение.** Матрицу $A$, главные миноры которой не равны нулю, можно единственным образом разложить в произведение $L_1 D U$, в котором $D$ &mdash; диагональная, а $L_1$ и $U$ &mdash; нижняя и верхняя треугольные матрицы с единицами на главной диагонали.\n",
    "\n",
    "Рассмотрим важный частный случай &mdash; $LDU$-разложение симметричной матрицы $S$.\n",
    "Тогда $S = U^\\top D L^\\top$, причём $U^\\top$ &mdash; нижняя, а $L^\\top$ &mdash; верхняя треугольны матрицы. В силу единственности разложениея получаем\n",
    "$$\n",
    "  S = U^\\top D U.\n",
    "$$\n",
    "\n",
    "Если к тому же $S$ положительно определена, то все диагональные элементы матрицы $D$ положительны и мы можем ввести матрицы $D^{1/2} = \\mathrm{diag}\\left(\\sqrt{d_1}, \\dots, \\sqrt{d_n}\\right)$ и $V = D^{1/2}U$. Тогда мы получаем *разложение Холецкого*\n",
    "$$\n",
    "  S = V^\\top V.\n",
    "$$\n",
    "Разложение Холецкого играет заметную роль в численных методах, так как существует эффективный алгоритм, позволяющий получить его для положительно определённой симметричной матрицы $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. $\\mathbf{QR}$-разложение ###\n",
    "\n",
    "Большую роль в численных методах играет разложение *квадратной матрицы* $A$ на ортогональную матрицу $Q$ и верхнетреугольную матрицу $R$.\n",
    "$$\n",
    "  A = QR.\n",
    "$$\n",
    "\n",
    "**Предложение 1.** Любая квадратная матрица $A$ может быть разложена в произведение $QR$. \\\n",
    "**Предложение 2.** Если матрица $A$ невырождена, то её $QR$-разложение, в котором диагональные элементы $R$ положительны, единственно. \\\n",
    "**Предложение 3.** $QR$-разложение тесно связано с процессом ортогонализации Грама &mdash; Шмидта. Действительно, $AU = Q$ равносильно $QR$-разложению с $R = U^{-1}$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Пример.** Рассмотрим систему линейных уравнений $A\\mathbf{x} = \\mathbf{b}$. Используя $QR$-разложение матрицы $A$, получим\n",
    "\n",
    "$$\n",
    "  QR \\mathbf{x} = \\mathbf{b}, \\\\\n",
    "  R \\mathbf{x} = Q^\\top \\mathbf{b}.\n",
    "$$\n",
    "\n",
    "И в случе невырожденной $R$\n",
    "$$\n",
    "  \\mathbf{x} = R^{-1}Q^\\top \\mathbf{b}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2*. $\\mathbf{QR}$-разложение для прямоугольных матриц ###\n",
    "\n",
    "Произвольную матрицу размером $m \\times n$ можно представить в виде разложения\n",
    "$$\n",
    "  A = QR,\n",
    "$$\n",
    "где $Q$ &mdash; ортогональная матрица порядка $m$, а $R$ &mdash; матрица размеров $m \\times n$, элементы $r_{ij}$ которой удовлетворяют условию $r_{ij}=0$ при $i>j$.\n",
    "Такое разложение назовём $Qr$-разложением, чтобы подчеркнуть, что матрица $R$, вообще говоря, не является квадратной.\n",
    "\n",
    "Второе обобщение $QR$-разложения можно получить, применяя метод ортогонализации Грама &mdash; Шмидта.\n",
    "Теперь матрица $Q$ размеров $m \\times n$ может рассматриваться как совокупность $n$ столбцов из некоторой ортогональной матрицы порядка $m$, а $R$ &mdash; квадратная верхняя треугольная матрица порядка $n$.\n",
    "Такое разложение будем называть $qR$-разложением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15. 10.  5.]\n",
      "[21.61904762  8.44754587 -0.06659349]\n",
      "[17.40803526  8.80182523  3.79013951]\n",
      "[16.20163488  9.13622911  4.66213601]\n",
      "[15.68775999  9.40382226  4.90841775]\n",
      "[15.42191778  9.59901909  4.97906313]\n",
      "[15.26848207  9.73376417  4.99775376]\n",
      "[15.17426408  9.82411948  5.00161644]\n",
      "[15.11436084  9.88391707  5.00172209]\n",
      "[15.07552099  9.92331317  5.00116584]\n",
      "[15.05005493  9.94926053  5.00068455]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "D = np.diag((15, 10, 5))\n",
    "B = np.random.randint(0, 10, (3,3))\n",
    "# print(B)\n",
    "A = B @ D @ LA.inv(B)\n",
    "print(LA.eigvals(A))\n",
    "\n",
    "A1 = A\n",
    "for i in range(10):\n",
    "    Q, R = LA.qr(A1)\n",
    "    A1 = R@Q\n",
    "    print(np.diag(A1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],[2,1,3],[3,1,4]])\n",
    "C = np.array([[1,2],[2,1],[3,1]])\n",
    "R = np.array([[1,2,3],[2,1,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.33333333  0.66666667]\n",
      " [ 0.66666667 -0.33333333]]\n",
      "[[1. 2. 3.]\n",
      " [2. 1. 3.]\n",
      " [3. 1. 4.]]\n"
     ]
    }
   ],
   "source": [
    "M = LA.inv(C.T@C) @ (C.T@A@R.T) @ LA.inv(R@R.T)\n",
    "print(M)\n",
    "B = C@M@R\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Литература ##\n",
    "\n",
    "1. G. Strang. Linear algebra and learning from data. Wellesley-Cambridge Press, 2019. 432 p.\n",
    "1. Д.В. Беклемишев. Дополнительные главы линейной алгебры. М.: Наука, 1983. 336 с."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
