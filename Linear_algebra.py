# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:light
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.5.2
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# + [markdown] slideshow={"slide_type": "slide"}
# # Основные сведения из линейной алгебры &mdash; 1 #
# **
# -

import numpy as np
from numpy import linalg as LA

# ## Введение ##
#
# Что мы хотим вспомнить из линейной алгебры? Мы хотим уметь решать пять базовых задач:
#
# 1. Найти $x$ в уравнении $Ax = b$;
# 1. Найти $x$ и $\lambda$ в уравнении $Ax = \lambda x$;
# 1. Найти $v$, $u$ и $\sigma$ в уравнении $Av = \sigma u$;
# 1. Найти минимум выражения $\dfrac{\lVert Ax \rVert^2}{\lVert x \rVert^2}$;
# 1. Найти разложение матрицы $A$.
#
#
# 1. Можно ли вектор $b$ представить в виде линейной комбинации векторов матрицы $A$?
# 1. Вектор $Ax$ имеет то же направление, что и вектор $x$. Вдоль этого направления все сложные взаимодействия с матрицей $A$ чрезвычайно упрощаются. Вектор $A^2 x$ становится просто $\lambda^2 x$, матрица $e^{At}$ &mdash; $e^{\lambda t}$. Все действия становятся линейными.
# 1. Уравнение $Av = \sigma u$ похоже на предыдущее. Но матрица $A$ больше не квадратная. Это сингулярное разложение
# 1. Минимизация и факторизация являются фундаментальными прикладными задачами.

# ---

# ## Умножение матриц (4 способа) ##
#
# Давайте начнём с умножения матриц.
# $$ A \cdot B = C $$
#
# 1. Строка на столбец
# 1. Столбец на строку
# 1. Столбец на столбец
# 1. Строка на строку
#
# Для начала введём обозначения. Вектор будем записывать в виде столбца и обозначать стрелочкой $\vec{a}$ или жирной буквой $\mathbf{a}$.
# Строку будем обозначать с помощью звёздочки $\vec{a}^*$ или $\mathbf{a}^*$:
# $$
#   \mathbf{a} =
#   \begin{pmatrix}
#      a_1    \\
#      \cdots \\
#      a_n    \\
#   \end{pmatrix},
#   \mathbf{a}^* = (a_1, \ldots, a_n).
# $$

# ### Способ 1: &laquo;строка на столбец&raquo; ###
#
# Это стандартный способ умножения матриц: $c_{ij} = \mathbf{a}_i^* \cdot \mathbf{b}_j$.
#
# **Пример 1.** Скалярное произведение векторов $\mathbf{a}$ и $\mathbf{b}$:
# $$ (\mathbf{a}, \mathbf{b}) = \mathbf{a}^\top \cdot \mathbf{b}. $$

# ### Способ 2: &laquo;столбец на строку&raquo; ###
#
# Об иногда забывают, но матрицы можно умножать и по-другому. Произведение $AB$ равно *сумме произвдений* всех столбцов матрицы $A$ на соотвествующий строки матрицы $B$.
# $$ A \cdot B = \sum_i \mathbf{a}_i \cdot \mathbf{b}_i^*. $$
#
# **Пример 2.**
# $$
#   \begin{pmatrix}
#      1 & 2 \\
#      0 & 2 \\
#   \end{pmatrix}
#   \cdot
#   \begin{pmatrix}
#      0 & 5 \\
#      1 & 1 \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#      1 \\
#      0 \\
#   \end{pmatrix}
#   \cdot
#   \begin{pmatrix}
#      0 & 5 \\
#   \end{pmatrix}
#   +
#   \begin{pmatrix}
#      2 \\
#      2 \\
#   \end{pmatrix}
#   \cdot
#   \begin{pmatrix}
#      1 & 1 \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#      0 & 5 \\
#      0 & 0 \\
#   \end{pmatrix}
#   +
#   \begin{pmatrix}
#      2 & 2 \\
#      2 & 2 \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#      2 & 7 \\
#      2 & 2 \\
#   \end{pmatrix}.
# $$

# ### Способ 3: &laquo;столбец на столбец&raquo; ###
#
# Посмотрим внимательном на то, как мы поличили первый столбец результирующий матрицы.
# Он является суммой столбцов матрицы $A$ с коэффициентами из первого столбца матрицы $B$!
# То же самое можно сказать и про второй столбец.
# Таким образом, можно сформулировать следующее правило: \
# *$\mathbf{i}$-ый столбец результирующий матрицы есть сумма всех столбцов левой матрицы с коэффициентами из $\mathbf{i}$-ого столбца правой матрицы.*

# ### Способ 4: &laquo;строка на строку&raquo; ###
#
# Аналогичным образом можно вывести правило и для строк: \
# *$\mathbf{i}$-ая строка результирующий матрицы есть сумма всех строк правой матрицы с коэффициентами из $\mathbf{i}$-ой строки левой матрицы.*

# + [markdown] slideshow={"slide_type": "slide"}
# **Пример 3. Умножение матрицы на вектор**
#
# Рассмотрим умножение матрицы $A$ размером $l \times n$ на вектор: $A \mathbf{x}$.
#
# По определению произведение $A \mathbf{x}$ есть вектор, в котором на $i$-ом месте находится скалярное произведение $i$-ой *строки* на столбец $\mathbf{x}$:
# $$
#   A \mathbf{x} = 
#   \begin{pmatrix}
#     -\, \mathbf{a}_1^* \,- \\
#     \cdots \\
#     -\, \mathbf{a}_i^* \,- \\
#     \cdots \\
#     -\, \mathbf{a}_m^* \,- \\
#   \end{pmatrix}
#   \cdot \mathbf{x} = 
#   \begin{pmatrix}
#     \mathbf{a}_1^* \cdot \mathbf{x} \\
#     \cdots \\
#     \mathbf{a}_i^* \cdot \mathbf{x} \\
#     \cdots \\
#     \mathbf{a}_m^* \cdot \mathbf{x} \\
#   \end{pmatrix}.
# $$
#
# Но можно посмотреть на это иначе, как на произведение *столбцов* матрицы $A$ на элементы вектора $\mathbf{x}$:
# $$
#   A \mathbf{x} = 
#   \begin{pmatrix}
#      | & {} & | & {} & | \\
#      \mathbf{a}_1 & \cdots & \mathbf{a}_i & \cdots & \mathbf{a}_n \\
#      | & {} & | & {} & | \\
#   \end{pmatrix}
#   \begin{pmatrix}
#      x_1    \\
#      \cdots \\
#      x_i    \\
#      \cdots \\
#      x_m \\
#   \end{pmatrix}
#   = 
#   x_1 \mathbf{a}_1 + \dots + x_i \mathbf{a}_i + \dots + x_m \mathbf{a}_m.
# $$
# Таким образом, результирующий вектор есть *линейная комбинация* столбцов матрицы $A$ с коэффициентами из вектора $\mathbf{x}$.
# -

# **Пример 4. Умножение столбцов (строк) матрицы на скаляры**
#
# Чтобы каждый вектор матрицы $A$ умножить на скаляр $\lambda_i$, нужно умножить $A$ на матрицу $\Lambda = \mathrm{diag}(\lambda_i)$ *справа*:
# $$
#   \begin{pmatrix}
#     | & {} & | \\
#     \lambda_1 \mathbf{a}_1 & \cdots & \lambda_n \mathbf{a}_n \\
#     | & {} & | \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#     | & {} & | \\
#     \mathbf{a}_1 & \cdots & \mathbf{a}_n \\
#     | & {} & | \\
#   \end{pmatrix}
#   \begin{pmatrix}
#     \lambda_{1} & \ldots & 0         \\
#     \vdots      & \ddots & \vdots    \\
#     0           & \ldots & \lambda_n \\
#   \end{pmatrix}
#   = A \cdot \Lambda.
# $$
#
# Чтобы проделать то же самое со строками матрицы, её нужно умножить на $\Lambda$ *слева*:
# $$
#   \begin{pmatrix}
#     -\, \lambda_1 \mathbf{a}_1^* \,- \\
#     \cdots \\
#     -\, \lambda_m \mathbf{a}_m^* \,- \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#     \lambda_{1} & \ldots & 0         \\
#     \vdots      & \ddots & \vdots    \\
#     0           & \ldots & \lambda_n \\
#   \end{pmatrix}
#   \begin{pmatrix}
#     -\, \mathbf{a}_1^* \,- \\
#     \cdots \\
#     -\, \mathbf{a}_m^* \,- \\
#   \end{pmatrix}
#   = \Lambda \cdot A.
# $$

# **Пример 5. Умножение блочных матриц**
#
# Рассмотрим блочную матрицу следующего вида: 
# $$ A = \begin{pmatrix} A_1 \\ A_2 \\ \end{pmatrix}. $$
#
# 1. Формулу для $A A^\top$ получим по способу &laquo;строка на столбец&raquo;:
# $$
#   A A^\top = 
#   \begin{pmatrix}
#     A_1 \\
#     A_2 \\
#   \end{pmatrix}
#   \cdot
#   \begin{pmatrix}
#     A_1^\top & A_2^\top \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#     A_1 A_1^\top & A_1 A_2^\top \\
#     A_2 A_2^\top & A_2 A_2^\top \\
#   \end{pmatrix}
# $$
# 2. Для $A^\top A$ удобно применить способ &laquo;столбец на строку&raquo;:
# $$
#   A^\top A =
#   \begin{pmatrix}
#     A_1^\top & A_2^\top \\
#   \end{pmatrix}
#   \begin{pmatrix}
#     A_1 \\
#     A_2 \\
#   \end{pmatrix}
#   = A_1^\top A_1 + A_2^\top A_2
# $$

# ---

# ### Линейная оболочка, размерность пространства, ранг матрицы ###
#
# Посмтрим ещё раз на задачу $A \mathbf{x} = \mathbf{b}$. \
# Теперь её можно переформулировать так: ответить, можно ли столбец $\mathbf{b}$ представить в виде линейной комбинации столбцов матрицы $A$.
#
# Поясним на примере.
# Пусть
# $$
#   A = 
#   \begin{pmatrix}
#      1 & 2 & 3 \\
#      2 & 1 & 3 \\
#      3 & 1 & 4 \\
#   \end{pmatrix}.
# $$
# Что мы можем сказать о линейной оболочке её столбцов? Что это за пространство? Какой размерности?
#
# **Определение 1.** Рангом матрицы $A$ с $n$ строк и $m$ столбцов называется максимальное число линейно независимых столбцов (строк).

# > В матрице $A$ первые два вектора линейно независимы.
# > Попробуем взять их в качестве базиса и разложить по ним третий.
# > Запишем это в матричном виде, пользуясь правилом вмножения &laquo;столбец на столбец&raquo;.
# > Мы получлили скелетное разложение матрицы.
#
# **Определение 2.** *Скелетным разложением* матрицы $A$ размеров $m \times n$ и ранга $r>0$ называется разложение вида $A = CR$, где матрицы $C$ и $R$ имеют размеры соттвественно $m \times r$ и $r \times n$.
# Другое название скелетного разложения &mdash; ранговая факторизация.
#
# Так как ранг произведения не превосходит рангов сомножителей, а ранги $C$ и $R$ не могут быть больше $r$, то они равны $r$.
#
# $$
#   A = 
#   \begin{pmatrix}
#      1 & 2 & 3 \\
#      2 & 1 & 3 \\
#      3 & 1 & 4 \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#      1 & 2 \\
#      2 & 1 \\
#      3 & 1 \\
#   \end{pmatrix}
#   \cdot
#   \begin{pmatrix}
#      1 & 0 & 1 \\
#      0 & 1 & 1 \\
#   \end{pmatrix}
#   = C \cdot R.
# $$
#
# $C$ &mdash; базисные столбцы, $R$ &mdash; базисные строки.
# Это разложение доказывает теорему: ранг матрицы по столбцам (количество независимых столбцов) равен рангу матрицы по строкам (количество независимых строк).

# **Не рассказывать.**
#
# Существует другой вариант скелетного разложения: $A = CMR$.
# В этом случае матрица $С$, как и ранее, состоит из $r$ независимых столбцов матрицы $A$, матрица $R$ теперь состоит из $r$ независимых строк матрицы $A$, а матрица $M$ размером $r \times r$ называется смешанной матрицей (mixing matrix).
# Для $M$ можно получить следующую формулу:
# $$
#   A = CMR \\
#   C^\top A R^\top = C^\top C M R R^\top \\
#   M = (C^\top C)^{-1} (C^\top A R^\top) (R R^\top)^{-1}.
# $$
#
# Обратим внимание на используемый приём &mdash; домножение прямоугольной матрицы на транспонированную. Полученную квадратную матрицу (в случае если она невырожденная) можно уже домножать на обратную (&laquo;делить на матрицу&raquo;).

# ***Разложение матрицы на сумму матриц ранга 1.***
#
# Применяем умножение &laquo;столбец на строку&raquo;:
# $$
#   A = 
#   \begin{pmatrix}
#      1 & 2 & 3 \\
#      2 & 1 & 3 \\
#      3 & 1 & 4 \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#      1 & 2 \\
#      2 & 1 \\
#      3 & 1 \\
#   \end{pmatrix}
#   \cdot
#   \begin{pmatrix}
#      1 & 0 & 1 \\
#      0 & 1 & 1 \\
#   \end{pmatrix}
#   =
#   \begin{pmatrix}
#      1 & 0 & 1 \\
#      2 & 0 & 2 \\
#      3 & 0 & 3 \\
#   \end{pmatrix}
#   +
#   \begin{pmatrix}
#      0 & 2 & 2 \\
#      0 & 1 & 1 \\
#      0 & 1 & 1 \\
#   \end{pmatrix}.
# $$

# ---

# Вернемся к СЛАУ.
# Теорема Фредгольма в виде пространства столбцов, пространства строк и в виде ядро-образ.
#
# "Большая картина линейной алгебры".

# Разложения матриц.
#
# 1. LU
#
# 1. Приведение матрицы к диаггональному виду.
#
# Ортогональные матрицы (сложим ортонормированные вектора). Пример: вращение, отражение
# Симметричная матрица. Пример: ортогональная проекция, отражение (симметричная и ортогональная одновременно?).
#
# 1. Спектральное разложение симметричной матрицы.
#
# 1. QR, обобщение

# ## Замечательные матрицы ##
#
# 1. Симметричная матрица
# 1. Симметричная положительно определённая матрица
# 1. Ортогональная матрица
#
# **Примеры**: $A^\top A$, матрица ортогональной проекции, матрицы поворота и симметрии.

# ### Матрица ортогональной проекции ###
#
# Пусть заданы вектор $\mathbf{b}$ из $\mathbb{R}_m$ и набор векторов $\mathbf{a}_i$, образующих базис в $\mathbb{R}_n$ ($n<m$).
#
# Требуется найти ортогональную проекцию вектора $\mathbf{b}$ на линейную оболочку векторов $\mathbf{a}_i$.
#
# Искомый вектор является линейной комбинацией базисных векторов $\mathbf{a}_i$ с неизвестными коэффициентами $x_i$.
# Запишем это в виде произведения матрицы $A$, столбцы которой являются векторами $\mathbf{a}_i$, на неизвестный вектор $\mathbf{x}$: $A\mathbf{x}$.
# Мы ищем ортогональную проекцию на пространство столбцов матрицы $A$, поэтому вектор $A\mathbf{x} - \mathbf{b}$ должен быть ортогонален *любому* вектору $A\mathbf{y}$.
# Запишем это через скалярное произведение:
# $$
#   (A \mathbf{y})^\top(A\mathbf{x} - \mathbf{b}) = \mathbf{y}^\top (A^\top A \mathbf{x} - A^\top \mathbf{b}) = 0.
# $$
#
# Это српаведливо для произвольного вектора $\mathbf{y}$, откуда следует, что
# $$
#   A^\top A \mathbf{x} = A^\top \mathbf{b}.
# $$
#
# Ранг матрицы $A^\top A$ равен рангу $A$, а столбцы матрицы $A$ линейно независимы, следовательно матрица $A^\top A$ обратима.
# Отсюда находим выражение для вектора коэффициентов проекции и сам вектор проекции $\mathbf{p} = A\mathbf{x}$
# $$
#   \mathbf{x} = (A^\top A)^{-1} A^\top \mathbf{b}, \
#   \mathbf{p} = A (A^\top A)^{-1} A^\top \mathbf{b}.
# $$
#
# Матрица $P = A (A^\top A)^{-1} A^\top \mathbf{b}$, осуществляющая проекцию, называется *матрицей ортогонального проектирования*.
# Матрица ортопроектирования обладает двумя основными свойствами:
#
# 1. $P^2 = P$ &mdash; характеристическое свойство всех проекторов,
# 1. $P^\top = P$ &mdash; отличительное свойство ортогонального проектора.

# ---

# ## Разложения матриц##
#
# Рассмотрим пять замечательных разложений матриц
#
# 1. $A = LU$
# 1. $A = QR$
# 1. $A = X \Lambda X^{-1}$
# 1. $S = Q \Lambda Q^\top$
# 1. $A = U \Sigma V^\top$

# ### 1. $\mathbf{LU}$-разложение ###
#
# > Ограничения: матрица $A$ &mdash; квадратная и невырожденная

# #### Определение и критерий существования ####
#
# **Определение.** $LU$-разложением квадратной матрицы $A$ называется разложение матрицы $A$ в произведение $LU$ невырожденной нижней треугольной матрицы $L$ и верхней треугольной матрицы $U$ с единицами на главной диагонали.
#
# **Теорема (критерий существования).** $LU$-разложение матрицы $A$ существует тогда и только тогда, когда все главные миноры матрицы $A$ отличны от нуля. Если $LU$-разложение существует, то оно единственно.

# #### Метод Гаусса ####
#
# **Замечание.** $LU$-разложение можно рассматривать, как матричную форму записи метода исключения Гаусса.
#
# Пусть дана система линейных уравнений вида
# $$ A \mathbf{x} = \mathbf{b}, $$
# где $A$ &mdash; невырожденная квадратная матрица порядка $n$.
#
# Метод Гаусса состоит в том, что элементарными преобразованиями *строк* матрицы $A$ она превращается в единичную матрицу.
# Если преобразования производить над расширенной матрицей (включающей столбец свободных членов), то последний столбец превартится в решение системы.

# #### 1. Все главные миноры отличны от нуля ####
#
# Отличие от нуля главных миноров позволяет не включать в число производимых элементарных операций перестановки строк.
#
# Метод Гаусса можно разделить на два этапа: прямое исключение и обратная подстановка.
# Первым этапом решения СЛАУ методом Гаусса является процесс превращения матрицы $A$ элементарными преобразованиями в верхнюю треугольную матрицу $U$.
#
# Известно, что выполнение какой-лиюо элементарной операции со строками матрицы $A$ равносильно умножению $A$ *слева* на некоторую невырожденную матрицу, а последовательное выполнение ряда таких операций &mdash; умножению на матрицу $S$, равную произведению соотвествующих матриц.
#
# На этапе прямого исключения кроме умножения строк на числа употребляется  только прибавление строки к нижележащей строке.
# Следовательно матрица $S$ является нижней треугольной.
#
# **Предложение.** Для любой матрицы $A$ с ненулевыми главными минорами найдётся такая невырожденная нижняя треугольная матрица $S$, что $SA$ есть верхняя треугольная матрица $U$ с единицами на главной диагонали:
# $$ SA = U. $$
#
# Матрица $L$, обратная к нижней треугольной матрице $S$, сама является нижней треугольной.
# Тогда получаем:
# $$ A = LU. $$

# #### 2. Существуют ненулевые главные миноры ($\mathbf{LUP}$-разложение) ####
#
# Что делать, если не все главные миноры отличны от нуля?
# К используемым элементарным операциям нужно добавить перестановки строк.
#
# **Предложение.** Невырожденную матрицу $A$ перестановкой строк можно перевести в матрицу, главные миноры которой отличны от нуля.
#
# Тогда справедливо
# $$ PA = LU,$$
# где $P$ &mdash; матрица, полученная из единичной перестановками строк.

# #### $\mathbf{LDU}$-разложение ####
#
#
# **Замечание.** Единственным является разложение на такие треугольные множители, что у второго из них на главной диагонали стоят единицы. Вообще же существует много треугольних разложений, в частности такое, в котором единицы находятся на главной диагонли у первого сомножителя.
#
# Матрицу $L$ можно представить как произведение матрицы $L_1$, имеющей единицы на главной диагонали, и диагональной матрицы $D$. Тогда мы получим
#
# **Предложение.** Матрицу $A$, главные миноры которой не равны нулю, можно единственным образом разложить в произведение $L_1 D U$, в котором $D$ &mdash; диагональная, а $L_1$ и $U$ &mdash; нижняя и верхняя треугольные матрицы с единицами на главной диагонали.

# #### Разложение Холецкого ####
#
# Рассмотрим важный частный случай &mdash; $LDU$-разложение симметричной матрицы $S = LDU$. \
# Тогда $S^\top = U^\top D L^\top$, причём $U^\top$ &mdash; нижняя, а $L^\top$ &mdash; верхняя треугольны матрицы. \
# В силу единственности разложениея получаем
# $$ S = U^\top D U. $$
#
# Если к тому же $S$ положительно определена, то все диагональные элементы матрицы $D$ положительны и мы можем ввести матрицы $D^{1/2} = \mathrm{diag}\left(\sqrt{d_1}, \dots, \sqrt{d_n}\right)$ и $V = D^{1/2}U$. Тогда мы получаем *разложение Холецкого*
# $$
#   S = V^\top V.
# $$
# Разложение Холецкого играет заметную роль в численных методах, так как существует эффективный алгоритм, позволяющий получить его для положительно определённой симметричной матрицы $S$.

# ---

# ### 2. $\mathbf{QR}$-разложение ###
#
# Большую роль в численных методах играет разложение *квадратной матрицы* $A$ на ортогональную матрицу $Q$ и верхнетреугольную матрицу $R$.
# $$
#   A = QR.
# $$
#
# **Предложение 1.** Любая квадратная матрица $A$ может быть разложена в произведение $QR$. \
# **Предложение 2.** Если матрица $A$ невырождена, то её $QR$-разложение, в котором диагональные элементы $R$ положительны, единственно. \
# **Предложение 3.** $QR$-разложение тесно связано с процессом ортогонализации Грама &mdash; Шмидта. Действительно, $AU = Q$ равносильно $QR$-разложению с $R = U^{-1}$.
#
#
#
#
# **Пример.** Рассмотрим систему линейных уравнений $A\mathbf{x} = \mathbf{b}$. Используя $QR$-разложение матрицы $A$, получим
#
# $$
#   QR \mathbf{x} = \mathbf{b}, \\
#   R \mathbf{x} = Q^\top \mathbf{b}.
# $$
#
# И в случе невырожденной $R$
# $$
#   \mathbf{x} = R^{-1}Q^\top \mathbf{b}.
# $$

# ### 2*. $\mathbf{QR}$-разложение для прямоугольных матриц ###
#
# Произвольную матрицу размером $m \times n$ можно представить в виде разложения
# $$
#   A = QR,
# $$
# где $Q$ &mdash; ортогональная матрица порядка $m$, а $R$ &mdash; матрица размеров $m \times n$, элементы $r_{ij}$ которой удовлетворяют условию $r_{ij}=0$ при $i>j$.
# Такое разложение назовём $Qr$-разложением, чтобы подчеркнуть, что матрица $R$, вообще говоря, не является квадратной.
#
# Второе обобщение $QR$-разложения можно получить, применяя метод ортогонализации Грама &mdash; Шмидта.
# Теперь матрица $Q$ размеров $m \times n$ может рассматриваться как совокупность $n$ столбцов из некоторой ортогональной матрицы порядка $m$, а $R$ &mdash; квадратная верхняя треугольная матрица порядка $n$.
# Такое разложение будем называть $qR$-разложением.







# +
np.random.seed(12345)

D = np.diag((15, 10, 5))
B = np.random.randint(0, 10, (3,3))
# print(B)
A = B @ D @ LA.inv(B)
print(LA.eigvals(A))

A1 = A
for i in range(10):
    Q, R = LA.qr(A1)
    A1 = R@Q
    print(np.diag(A1))
# -









import numpy as np
from numpy import linalg as LA

A = np.array([[1,2,3],[2,1,3],[3,1,4]])
C = np.array([[1,2],[2,1],[3,1]])
R = np.array([[1,2,3],[2,1,3]])

M = LA.inv(C.T@C) @ (C.T@A@R.T) @ LA.inv(R@R.T)
print(M)
B = C@M@R
print(B)

# + [markdown] slideshow={"slide_type": "skip"}
# ---

# + [markdown] slideshow={"slide_type": "slide"}
# ## Литература ##
#
# 1. G. Strang. Linear algebra and learning from data. Wellesley-Cambridge Press, 2019. 432 p.
# 1. Д.В. Беклемишев. Дополнительные главы линейной алгебры. М.: Наука, 1983. 336 с.
# -


